{"ast":null,"code":"'use strict'; // Last time updated: 2021-03-09 3:20:22 AM UTC\n// ________________\n// RecordRTC v5.6.2\n// Open-Sourced: https://github.com/muaz-khan/RecordRTC\n// --------------------------------------------------\n// Muaz Khan     - www.MuazKhan.com\n// MIT License   - www.WebRTC-Experiment.com/licence\n// --------------------------------------------------\n// ____________\n// RecordRTC.js\n\n/**\r\n * {@link https://github.com/muaz-khan/RecordRTC|RecordRTC} is a WebRTC JavaScript library for audio/video as well as screen activity recording. It supports Chrome, Firefox, Opera, Android, and Microsoft Edge. Platforms: Linux, Mac and Windows. \r\n * @summary Record audio, video or screen inside the browser.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef RecordRTC\r\n * @class\r\n * @example\r\n * var recorder = RecordRTC(mediaStream or [arrayOfMediaStream], {\r\n *     type: 'video', // audio or video or gif or canvas\r\n *     recorderType: MediaStreamRecorder || CanvasRecorder || StereoAudioRecorder || Etc\r\n * });\r\n * recorder.startRecording();\r\n * @see For further information:\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.\r\n * @param {object} config - {type:\"video\", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, desiredSampRate: 16000, video: HTMLVideoElement, etc.}\r\n */\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") { _typeof = function _typeof(obj) { return typeof obj; }; } else { _typeof = function _typeof(obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }; } return _typeof(obj); }\n\nfunction RecordRTC(mediaStream, config) {\n  if (!mediaStream) {\n    throw 'First parameter is required.';\n  }\n\n  config = config || {\n    type: 'video'\n  };\n  config = new RecordRTCConfiguration(mediaStream, config); // a reference to user's recordRTC object\n\n  var self = this;\n\n  function startRecording(config2) {\n    if (!config.disableLogs) {\n      console.log('RecordRTC version: ', self.version);\n    }\n\n    if (!!config2) {\n      // allow users to set options using startRecording method\n      // config2 is similar to main \"config\" object (second parameter over RecordRTC constructor)\n      config = new RecordRTCConfiguration(mediaStream, config2);\n    }\n\n    if (!config.disableLogs) {\n      console.log('started recording ' + config.type + ' stream.');\n    }\n\n    if (mediaRecorder) {\n      mediaRecorder.clearRecordedData();\n      mediaRecorder.record();\n      setState('recording');\n\n      if (self.recordingDuration) {\n        handleRecordingDuration();\n      }\n\n      return self;\n    }\n\n    initRecorder(function () {\n      if (self.recordingDuration) {\n        handleRecordingDuration();\n      }\n    });\n    return self;\n  }\n\n  function initRecorder(initCallback) {\n    if (initCallback) {\n      config.initCallback = function () {\n        initCallback();\n        initCallback = config.initCallback = null; // recorder.initRecorder should be call-backed once.\n      };\n    }\n\n    var Recorder = new GetRecorderType(mediaStream, config);\n    mediaRecorder = new Recorder(mediaStream, config);\n    mediaRecorder.record();\n    setState('recording');\n\n    if (!config.disableLogs) {\n      console.log('Initialized recorderType:', mediaRecorder.constructor.name, 'for output-type:', config.type);\n    }\n  }\n\n  function stopRecording(callback) {\n    callback = callback || function () {};\n\n    if (!mediaRecorder) {\n      warningLog();\n      return;\n    }\n\n    if (self.state === 'paused') {\n      self.resumeRecording();\n      setTimeout(function () {\n        stopRecording(callback);\n      }, 1);\n      return;\n    }\n\n    if (self.state !== 'recording' && !config.disableLogs) {\n      console.warn('Recording state should be: \"recording\", however current state is: ', self.state);\n    }\n\n    if (!config.disableLogs) {\n      console.log('Stopped recording ' + config.type + ' stream.');\n    }\n\n    if (config.type !== 'gif') {\n      mediaRecorder.stop(_callback);\n    } else {\n      mediaRecorder.stop();\n\n      _callback();\n    }\n\n    setState('stopped');\n\n    function _callback(__blob) {\n      if (!mediaRecorder) {\n        if (typeof callback.call === 'function') {\n          callback.call(self, '');\n        } else {\n          callback('');\n        }\n\n        return;\n      }\n\n      Object.keys(mediaRecorder).forEach(function (key) {\n        if (typeof mediaRecorder[key] === 'function') {\n          return;\n        }\n\n        self[key] = mediaRecorder[key];\n      });\n      var blob = mediaRecorder.blob;\n\n      if (!blob) {\n        if (__blob) {\n          mediaRecorder.blob = blob = __blob;\n        } else {\n          throw 'Recording failed.';\n        }\n      }\n\n      if (blob && !config.disableLogs) {\n        console.log(blob.type, '->', bytesToSize(blob.size));\n      }\n\n      if (callback) {\n        var url;\n\n        try {\n          url = URL.createObjectURL(blob);\n        } catch (e) {}\n\n        if (typeof callback.call === 'function') {\n          callback.call(self, url);\n        } else {\n          callback(url);\n        }\n      }\n\n      if (!config.autoWriteToDisk) {\n        return;\n      }\n\n      getDataURL(function (dataURL) {\n        var parameter = {};\n        parameter[config.type + 'Blob'] = dataURL;\n        DiskStorage.Store(parameter);\n      });\n    }\n  }\n\n  function pauseRecording() {\n    if (!mediaRecorder) {\n      warningLog();\n      return;\n    }\n\n    if (self.state !== 'recording') {\n      if (!config.disableLogs) {\n        console.warn('Unable to pause the recording. Recording state: ', self.state);\n      }\n\n      return;\n    }\n\n    setState('paused');\n    mediaRecorder.pause();\n\n    if (!config.disableLogs) {\n      console.log('Paused recording.');\n    }\n  }\n\n  function resumeRecording() {\n    if (!mediaRecorder) {\n      warningLog();\n      return;\n    }\n\n    if (self.state !== 'paused') {\n      if (!config.disableLogs) {\n        console.warn('Unable to resume the recording. Recording state: ', self.state);\n      }\n\n      return;\n    }\n\n    setState('recording'); // not all libs have this method yet\n\n    mediaRecorder.resume();\n\n    if (!config.disableLogs) {\n      console.log('Resumed recording.');\n    }\n  }\n\n  function readFile(_blob) {\n    postMessage(new FileReaderSync().readAsDataURL(_blob));\n  }\n\n  function getDataURL(callback, _mediaRecorder) {\n    if (!callback) {\n      throw 'Pass a callback function over getDataURL.';\n    }\n\n    var blob = _mediaRecorder ? _mediaRecorder.blob : (mediaRecorder || {}).blob;\n\n    if (!blob) {\n      if (!config.disableLogs) {\n        console.warn('Blob encoder did not finish its job yet.');\n      }\n\n      setTimeout(function () {\n        getDataURL(callback, _mediaRecorder);\n      }, 1000);\n      return;\n    }\n\n    if (typeof Worker !== 'undefined' && !navigator.mozGetUserMedia) {\n      var webWorker = processInWebWorker(readFile);\n\n      webWorker.onmessage = function (event) {\n        callback(event.data);\n      };\n\n      webWorker.postMessage(blob);\n    } else {\n      var reader = new FileReader();\n      reader.readAsDataURL(blob);\n\n      reader.onload = function (event) {\n        callback(event.target.result);\n      };\n    }\n\n    function processInWebWorker(_function) {\n      try {\n        var blob = URL.createObjectURL(new Blob([_function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'], {\n          type: 'application/javascript'\n        }));\n        var worker = new Worker(blob);\n        URL.revokeObjectURL(blob);\n        return worker;\n      } catch (e) {}\n    }\n  }\n\n  function handleRecordingDuration(counter) {\n    counter = counter || 0;\n\n    if (self.state === 'paused') {\n      setTimeout(function () {\n        handleRecordingDuration(counter);\n      }, 1000);\n      return;\n    }\n\n    if (self.state === 'stopped') {\n      return;\n    }\n\n    if (counter >= self.recordingDuration) {\n      stopRecording(self.onRecordingStopped);\n      return;\n    }\n\n    counter += 1000; // 1-second\n\n    setTimeout(function () {\n      handleRecordingDuration(counter);\n    }, 1000);\n  }\n\n  function setState(state) {\n    if (!self) {\n      return;\n    }\n\n    self.state = state;\n\n    if (typeof self.onStateChanged.call === 'function') {\n      self.onStateChanged.call(self, state);\n    } else {\n      self.onStateChanged(state);\n    }\n  }\n\n  var WARNING = 'It seems that recorder is destroyed or \"startRecording\" is not invoked for ' + config.type + ' recorder.';\n\n  function warningLog() {\n    if (config.disableLogs === true) {\n      return;\n    }\n\n    console.warn(WARNING);\n  }\n\n  var mediaRecorder;\n  var returnObject = {\n    /**\r\n     * This method starts the recording.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * var recorder = RecordRTC(mediaStream, {\r\n     *     type: 'video'\r\n     * });\r\n     * recorder.startRecording();\r\n     */\n    startRecording: startRecording,\n\n    /**\r\n     * This method stops the recording. It is strongly recommended to get \"blob\" or \"URI\" inside the callback to make sure all recorders finished their job.\r\n     * @param {function} callback - Callback to get the recorded blob.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     // use either \"this\" or \"recorder\" object; both are identical\r\n     *     video.src = this.toURL();\r\n     *     var blob = this.getBlob();\r\n     * });\r\n     */\n    stopRecording: stopRecording,\n\n    /**\r\n     * This method pauses the recording. You can resume recording using \"resumeRecording\" method.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @todo Firefox is unable to pause the recording. Fix it.\r\n     * @example\r\n     * recorder.pauseRecording();  // pause the recording\r\n     * recorder.resumeRecording(); // resume again\r\n     */\n    pauseRecording: pauseRecording,\n\n    /**\r\n     * This method resumes the recording.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.pauseRecording();  // first of all, pause the recording\r\n     * recorder.resumeRecording(); // now resume it\r\n     */\n    resumeRecording: resumeRecording,\n\n    /**\r\n     * This method initializes the recording.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @todo This method should be deprecated.\r\n     * @example\r\n     * recorder.initRecorder();\r\n     */\n    initRecorder: initRecorder,\n\n    /**\r\n     * Ask RecordRTC to auto-stop the recording after 5 minutes.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * var fiveMinutes = 5 * 1000 * 60;\r\n     * recorder.setRecordingDuration(fiveMinutes, function() {\r\n     *    var blob = this.getBlob();\r\n     *    video.src = this.toURL();\r\n     * });\r\n     * \r\n     * // or otherwise\r\n     * recorder.setRecordingDuration(fiveMinutes).onRecordingStopped(function() {\r\n     *    var blob = this.getBlob();\r\n     *    video.src = this.toURL();\r\n     * });\r\n     */\n    setRecordingDuration: function setRecordingDuration(recordingDuration, callback) {\n      if (typeof recordingDuration === 'undefined') {\n        throw 'recordingDuration is required.';\n      }\n\n      if (typeof recordingDuration !== 'number') {\n        throw 'recordingDuration must be a number.';\n      }\n\n      self.recordingDuration = recordingDuration;\n\n      self.onRecordingStopped = callback || function () {};\n\n      return {\n        onRecordingStopped: function onRecordingStopped(callback) {\n          self.onRecordingStopped = callback;\n        }\n      };\n    },\n\n    /**\r\n     * This method can be used to clear/reset all the recorded data.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @todo Figure out the difference between \"reset\" and \"clearRecordedData\" methods.\r\n     * @example\r\n     * recorder.clearRecordedData();\r\n     */\n    clearRecordedData: function clearRecordedData() {\n      if (!mediaRecorder) {\n        warningLog();\n        return;\n      }\n\n      mediaRecorder.clearRecordedData();\n\n      if (!config.disableLogs) {\n        console.log('Cleared old recorded data.');\n      }\n    },\n\n    /**\r\n     * Get the recorded blob. Use this method inside the \"stopRecording\" callback.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     var blob = this.getBlob();\r\n     *\r\n     *     var file = new File([blob], 'filename.webm', {\r\n     *         type: 'video/webm'\r\n     *     });\r\n     *\r\n     *     var formData = new FormData();\r\n     *     formData.append('file', file); // upload \"File\" object rather than a \"Blob\"\r\n     *     uploadToServer(formData);\r\n     * });\r\n     * @returns {Blob} Returns recorded data as \"Blob\" object.\r\n     */\n    getBlob: function getBlob() {\n      if (!mediaRecorder) {\n        warningLog();\n        return;\n      }\n\n      return mediaRecorder.blob;\n    },\n\n    /**\r\n     * Get data-URI instead of Blob.\r\n     * @param {function} callback - Callback to get the Data-URI.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     recorder.getDataURL(function(dataURI) {\r\n     *         video.src = dataURI;\r\n     *     });\r\n     * });\r\n     */\n    getDataURL: getDataURL,\n\n    /**\r\n     * Get virtual/temporary URL. Usage of this URL is limited to current tab.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     video.src = this.toURL();\r\n     * });\r\n     * @returns {String} Returns a virtual/temporary URL for the recorded \"Blob\".\r\n     */\n    toURL: function toURL() {\n      if (!mediaRecorder) {\n        warningLog();\n        return;\n      }\n\n      return URL.createObjectURL(mediaRecorder.blob);\n    },\n\n    /**\r\n     * Get internal recording object (i.e. internal module) e.g. MutliStreamRecorder, MediaStreamRecorder, StereoAudioRecorder or WhammyRecorder etc.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * var internalRecorder = recorder.getInternalRecorder();\r\n     * if(internalRecorder instanceof MultiStreamRecorder) {\r\n     *     internalRecorder.addStreams([newAudioStream]);\r\n     *     internalRecorder.resetVideoStreams([screenStream]);\r\n     * }\r\n     * @returns {Object} Returns internal recording object.\r\n     */\n    getInternalRecorder: function getInternalRecorder() {\n      return mediaRecorder;\n    },\n\n    /**\r\n     * Invoke save-as dialog to save the recorded blob into your disk.\r\n     * @param {string} fileName - Set your own file name.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     this.save('file-name');\r\n     *\r\n     *     // or manually:\r\n     *     invokeSaveAsDialog(this.getBlob(), 'filename.webm');\r\n     * });\r\n     */\n    save: function save(fileName) {\n      if (!mediaRecorder) {\n        warningLog();\n        return;\n      }\n\n      invokeSaveAsDialog(mediaRecorder.blob, fileName);\n    },\n\n    /**\r\n     * This method gets a blob from indexed-DB storage.\r\n     * @param {function} callback - Callback to get the recorded blob.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.getFromDisk(function(dataURL) {\r\n     *     video.src = dataURL;\r\n     * });\r\n     */\n    getFromDisk: function getFromDisk(callback) {\n      if (!mediaRecorder) {\n        warningLog();\n        return;\n      }\n\n      RecordRTC.getFromDisk(config.type, callback);\n    },\n\n    /**\r\n     * This method appends an array of webp images to the recorded video-blob. It takes an \"array\" object.\r\n     * @type {Array.<Array>}\r\n     * @param {Array} arrayOfWebPImages - Array of webp images.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @todo This method should be deprecated.\r\n     * @example\r\n     * var arrayOfWebPImages = [];\r\n     * arrayOfWebPImages.push({\r\n     *     duration: index,\r\n     *     image: 'data:image/webp;base64,...'\r\n     * });\r\n     * recorder.setAdvertisementArray(arrayOfWebPImages);\r\n     */\n    setAdvertisementArray: function setAdvertisementArray(arrayOfWebPImages) {\n      config.advertisement = [];\n      var length = arrayOfWebPImages.length;\n\n      for (var i = 0; i < length; i++) {\n        config.advertisement.push({\n          duration: i,\n          image: arrayOfWebPImages[i]\n        });\n      }\n    },\n\n    /**\r\n     * It is equivalent to <code class=\"str\">\"recorder.getBlob()\"</code> method. Usage of \"getBlob\" is recommended, though.\r\n     * @property {Blob} blob - Recorded Blob can be accessed using this property.\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @readonly\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     var blob = this.blob;\r\n     *\r\n     *     // below one is recommended\r\n     *     var blob = this.getBlob();\r\n     * });\r\n     */\n    blob: null,\n\n    /**\r\n     * This works only with {recorderType:StereoAudioRecorder}. Use this property on \"stopRecording\" to verify the encoder's sample-rates.\r\n     * @property {number} bufferSize - Buffer-size used to encode the WAV container\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @readonly\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     alert('Recorder used this buffer-size: ' + this.bufferSize);\r\n     * });\r\n     */\n    bufferSize: 0,\n\n    /**\r\n     * This works only with {recorderType:StereoAudioRecorder}. Use this property on \"stopRecording\" to verify the encoder's sample-rates.\r\n     * @property {number} sampleRate - Sample-rates used to encode the WAV container\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @readonly\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     alert('Recorder used these sample-rates: ' + this.sampleRate);\r\n     * });\r\n     */\n    sampleRate: 0,\n\n    /**\r\n     * {recorderType:StereoAudioRecorder} returns ArrayBuffer object.\r\n     * @property {ArrayBuffer} buffer - Audio ArrayBuffer, supported only in Chrome.\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @readonly\r\n     * @example\r\n     * recorder.stopRecording(function() {\r\n     *     var arrayBuffer = this.buffer;\r\n     *     alert(arrayBuffer.byteLength);\r\n     * });\r\n     */\n    buffer: null,\n\n    /**\r\n     * This method resets the recorder. So that you can reuse single recorder instance many times.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.reset();\r\n     * recorder.startRecording();\r\n     */\n    reset: function reset() {\n      if (self.state === 'recording' && !config.disableLogs) {\n        console.warn('Stop an active recorder.');\n      }\n\n      if (mediaRecorder && typeof mediaRecorder.clearRecordedData === 'function') {\n        mediaRecorder.clearRecordedData();\n      }\n\n      mediaRecorder = null;\n      setState('inactive');\n      self.blob = null;\n    },\n\n    /**\r\n     * This method is called whenever recorder's state changes. Use this as an \"event\".\r\n     * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @instance\r\n     * @example\r\n     * recorder.onStateChanged = function(state) {\r\n     *     console.log('Recorder state: ', state);\r\n     * };\r\n     */\n    onStateChanged: function onStateChanged(state) {\n      if (!config.disableLogs) {\n        console.log('Recorder state changed:', state);\n      }\n    },\n\n    /**\r\n     * A recorder can have inactive, recording, paused or stopped states.\r\n     * @property {String} state - A recorder's state can be: recording, paused, stopped or inactive.\r\n     * @memberof RecordRTC\r\n     * @static\r\n     * @readonly\r\n     * @example\r\n     * // this looper function will keep you updated about the recorder's states.\r\n     * (function looper() {\r\n     *     document.querySelector('h1').innerHTML = 'Recorder\\'s state is: ' + recorder.state;\r\n     *     if(recorder.state === 'stopped') return; // ignore+stop\r\n     *     setTimeout(looper, 1000); // update after every 3-seconds\r\n     * })();\r\n     * recorder.startRecording();\r\n     */\n    state: 'inactive',\n\n    /**\r\n     * Get recorder's readonly state.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @example\r\n     * var state = recorder.getState();\r\n     * @returns {String} Returns recording state.\r\n     */\n    getState: function getState() {\n      return self.state;\n    },\n\n    /**\r\n     * Destroy RecordRTC instance. Clear all recorders and objects.\r\n     * @method\r\n     * @memberof RecordRTC\r\n     * @example\r\n     * recorder.destroy();\r\n     */\n    destroy: function destroy() {\n      var disableLogsCache = config.disableLogs;\n      config = {\n        disableLogs: true\n      };\n      self.reset();\n      setState('destroyed');\n      returnObject = self = null;\n\n      if (Storage.AudioContextConstructor) {\n        Storage.AudioContextConstructor.close();\n        Storage.AudioContextConstructor = null;\n      }\n\n      config.disableLogs = disableLogsCache;\n\n      if (!config.disableLogs) {\n        console.log('RecordRTC is destroyed.');\n      }\n    },\n\n    /**\r\n     * RecordRTC version number\r\n     * @property {String} version - Release version number.\r\n     * @memberof RecordRTC\r\n     * @static\r\n     * @readonly\r\n     * @example\r\n     * alert(recorder.version);\r\n     */\n    version: '5.6.2'\n  };\n\n  if (!this) {\n    self = returnObject;\n    return returnObject;\n  } // if someone wants to use RecordRTC with the \"new\" keyword.\n\n\n  for (var prop in returnObject) {\n    this[prop] = returnObject[prop];\n  }\n\n  self = this;\n  return returnObject;\n}\n\nRecordRTC.version = '5.6.2';\n\nif (typeof module !== 'undefined'\n/* && !!module.exports*/\n) {\n    module.exports = RecordRTC;\n  }\n\nif (typeof define === 'function' && define.amd) {\n  define('RecordRTC', [], function () {\n    return RecordRTC;\n  });\n}\n\nRecordRTC.getFromDisk = function (type, callback) {\n  if (!callback) {\n    throw 'callback is mandatory.';\n  }\n\n  console.log('Getting recorded ' + (type === 'all' ? 'blobs' : type + ' blob ') + ' from disk!');\n  DiskStorage.Fetch(function (dataURL, _type) {\n    if (type !== 'all' && _type === type + 'Blob' && callback) {\n      callback(dataURL);\n    }\n\n    if (type === 'all' && callback) {\n      callback(dataURL, _type.replace('Blob', ''));\n    }\n  });\n};\n/**\r\n * This method can be used to store recorded blobs into IndexedDB storage.\r\n * @param {object} options - {audio: Blob, video: Blob, gif: Blob}\r\n * @method\r\n * @memberof RecordRTC\r\n * @example\r\n * RecordRTC.writeToDisk({\r\n *     audio: audioBlob,\r\n *     video: videoBlob,\r\n *     gif  : gifBlob\r\n * });\r\n */\n\n\nRecordRTC.writeToDisk = function (options) {\n  console.log('Writing recorded blob(s) to disk!');\n  options = options || {};\n\n  if (options.audio && options.video && options.gif) {\n    options.audio.getDataURL(function (audioDataURL) {\n      options.video.getDataURL(function (videoDataURL) {\n        options.gif.getDataURL(function (gifDataURL) {\n          DiskStorage.Store({\n            audioBlob: audioDataURL,\n            videoBlob: videoDataURL,\n            gifBlob: gifDataURL\n          });\n        });\n      });\n    });\n  } else if (options.audio && options.video) {\n    options.audio.getDataURL(function (audioDataURL) {\n      options.video.getDataURL(function (videoDataURL) {\n        DiskStorage.Store({\n          audioBlob: audioDataURL,\n          videoBlob: videoDataURL\n        });\n      });\n    });\n  } else if (options.audio && options.gif) {\n    options.audio.getDataURL(function (audioDataURL) {\n      options.gif.getDataURL(function (gifDataURL) {\n        DiskStorage.Store({\n          audioBlob: audioDataURL,\n          gifBlob: gifDataURL\n        });\n      });\n    });\n  } else if (options.video && options.gif) {\n    options.video.getDataURL(function (videoDataURL) {\n      options.gif.getDataURL(function (gifDataURL) {\n        DiskStorage.Store({\n          videoBlob: videoDataURL,\n          gifBlob: gifDataURL\n        });\n      });\n    });\n  } else if (options.audio) {\n    options.audio.getDataURL(function (audioDataURL) {\n      DiskStorage.Store({\n        audioBlob: audioDataURL\n      });\n    });\n  } else if (options.video) {\n    options.video.getDataURL(function (videoDataURL) {\n      DiskStorage.Store({\n        videoBlob: videoDataURL\n      });\n    });\n  } else if (options.gif) {\n    options.gif.getDataURL(function (gifDataURL) {\n      DiskStorage.Store({\n        gifBlob: gifDataURL\n      });\n    });\n  }\n}; // __________________________\n// RecordRTC-Configuration.js\n\n/**\r\n * {@link RecordRTCConfiguration} is an inner/private helper for {@link RecordRTC}.\r\n * @summary It configures the 2nd parameter passed over {@link RecordRTC} and returns a valid \"config\" object.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef RecordRTCConfiguration\r\n * @class\r\n * @example\r\n * var options = RecordRTCConfiguration(mediaStream, options);\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {type:\"video\", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, getNativeBlob:true, etc.}\r\n */\n\n\nfunction RecordRTCConfiguration(mediaStream, config) {\n  if (!config.recorderType && !config.type) {\n    if (!!config.audio && !!config.video) {\n      config.type = 'video';\n    } else if (!!config.audio && !config.video) {\n      config.type = 'audio';\n    }\n  }\n\n  if (config.recorderType && !config.type) {\n    if (config.recorderType === WhammyRecorder || config.recorderType === CanvasRecorder || typeof WebAssemblyRecorder !== 'undefined' && config.recorderType === WebAssemblyRecorder) {\n      config.type = 'video';\n    } else if (config.recorderType === GifRecorder) {\n      config.type = 'gif';\n    } else if (config.recorderType === StereoAudioRecorder) {\n      config.type = 'audio';\n    } else if (config.recorderType === MediaStreamRecorder) {\n      if (getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length) {\n        config.type = 'video';\n      } else if (!getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length) {\n        config.type = 'video';\n      } else if (getTracks(mediaStream, 'audio').length && !getTracks(mediaStream, 'video').length) {\n        config.type = 'audio';\n      } else {// config.type = 'UnKnown';\n      }\n    }\n  }\n\n  if (typeof MediaStreamRecorder !== 'undefined' && typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype) {\n    if (!config.mimeType) {\n      config.mimeType = 'video/webm';\n    }\n\n    if (!config.type) {\n      config.type = config.mimeType.split('/')[0];\n    }\n\n    if (!config.bitsPerSecond) {// config.bitsPerSecond = 128000;\n    }\n  } // consider default type=audio\n\n\n  if (!config.type) {\n    if (config.mimeType) {\n      config.type = config.mimeType.split('/')[0];\n    }\n\n    if (!config.type) {\n      config.type = 'audio';\n    }\n  }\n\n  return config;\n} // __________________\n// GetRecorderType.js\n\n/**\r\n * {@link GetRecorderType} is an inner/private helper for {@link RecordRTC}.\r\n * @summary It returns best recorder-type available for your browser.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef GetRecorderType\r\n * @class\r\n * @example\r\n * var RecorderType = GetRecorderType(options);\r\n * var recorder = new RecorderType(options);\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {type:\"video\", disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}\r\n */\n\n\nfunction GetRecorderType(mediaStream, config) {\n  var recorder; // StereoAudioRecorder can work with all three: Edge, Firefox and Chrome\n  // todo: detect if it is Edge, then auto use: StereoAudioRecorder\n\n  if (isChrome || isEdge || isOpera) {\n    // Media Stream Recording API has not been implemented in chrome yet;\n    // That's why using WebAudio API to record stereo audio in WAV format\n    recorder = StereoAudioRecorder;\n  }\n\n  if (typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype && !isChrome) {\n    recorder = MediaStreamRecorder;\n  } // video recorder (in WebM format)\n\n\n  if (config.type === 'video' && (isChrome || isOpera)) {\n    recorder = WhammyRecorder;\n\n    if (typeof WebAssemblyRecorder !== 'undefined' && typeof ReadableStream !== 'undefined') {\n      recorder = WebAssemblyRecorder;\n    }\n  } // video recorder (in Gif format)\n\n\n  if (config.type === 'gif') {\n    recorder = GifRecorder;\n  } // html2canvas recording!\n\n\n  if (config.type === 'canvas') {\n    recorder = CanvasRecorder;\n  }\n\n  if (isMediaRecorderCompatible() && recorder !== CanvasRecorder && recorder !== GifRecorder && typeof MediaRecorder !== 'undefined' && 'requestData' in MediaRecorder.prototype) {\n    if (getTracks(mediaStream, 'video').length || getTracks(mediaStream, 'audio').length) {\n      // audio-only recording\n      if (config.type === 'audio') {\n        if (typeof MediaRecorder.isTypeSupported === 'function' && MediaRecorder.isTypeSupported('audio/webm')) {\n          recorder = MediaStreamRecorder;\n        } // else recorder = StereoAudioRecorder;\n\n      } else {\n        // video or screen tracks\n        if (typeof MediaRecorder.isTypeSupported === 'function' && MediaRecorder.isTypeSupported('video/webm')) {\n          recorder = MediaStreamRecorder;\n        }\n      }\n    }\n  }\n\n  if (mediaStream instanceof Array && mediaStream.length) {\n    recorder = MultiStreamRecorder;\n  }\n\n  if (config.recorderType) {\n    recorder = config.recorderType;\n  }\n\n  if (!config.disableLogs && !!recorder && !!recorder.name) {\n    console.log('Using recorderType:', recorder.name || recorder.constructor.name);\n  }\n\n  if (!recorder && isSafari) {\n    recorder = MediaStreamRecorder;\n  }\n\n  return recorder;\n} // _____________\n// MRecordRTC.js\n\n/**\r\n * MRecordRTC runs on top of {@link RecordRTC} to bring multiple recordings in a single place, by providing simple API.\r\n * @summary MRecordRTC stands for \"Multiple-RecordRTC\".\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef MRecordRTC\r\n * @class\r\n * @example\r\n * var recorder = new MRecordRTC();\r\n * recorder.addStream(MediaStream);\r\n * recorder.mediaType = {\r\n *     audio: true, // or StereoAudioRecorder or MediaStreamRecorder\r\n *     video: true, // or WhammyRecorder or MediaStreamRecorder or WebAssemblyRecorder or CanvasRecorder\r\n *     gif: true    // or GifRecorder\r\n * };\r\n * // mimeType is optional and should be set only in advance cases.\r\n * recorder.mimeType = {\r\n *     audio: 'audio/wav',\r\n *     video: 'video/webm',\r\n *     gif:   'image/gif'\r\n * };\r\n * recorder.startRecording();\r\n * @see For further information:\r\n * @see {@link https://github.com/muaz-khan/RecordRTC/tree/master/MRecordRTC|MRecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @requires {@link RecordRTC}\r\n */\n\n\nfunction MRecordRTC(mediaStream) {\n  /**\r\n   * This method attaches MediaStream object to {@link MRecordRTC}.\r\n   * @param {MediaStream} mediaStream - A MediaStream object, either fetched using getUserMedia API, or generated using captureStreamUntilEnded or WebAudio API.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.addStream(MediaStream);\r\n   */\n  this.addStream = function (_mediaStream) {\n    if (_mediaStream) {\n      mediaStream = _mediaStream;\n    }\n  };\n  /**\r\n   * This property can be used to set the recording type e.g. audio, or video, or gif, or canvas.\r\n   * @property {object} mediaType - {audio: true, video: true, gif: true}\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * var recorder = new MRecordRTC();\r\n   * recorder.mediaType = {\r\n   *     audio: true, // TRUE or StereoAudioRecorder or MediaStreamRecorder\r\n   *     video: true, // TRUE or WhammyRecorder or MediaStreamRecorder or WebAssemblyRecorder or CanvasRecorder\r\n   *     gif  : true  // TRUE or GifRecorder\r\n   * };\r\n   */\n\n\n  this.mediaType = {\n    audio: true,\n    video: true\n  };\n  /**\r\n   * This method starts recording.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.startRecording();\r\n   */\n\n  this.startRecording = function () {\n    var mediaType = this.mediaType;\n    var recorderType;\n    var mimeType = this.mimeType || {\n      audio: null,\n      video: null,\n      gif: null\n    };\n\n    if (typeof mediaType.audio !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'audio').length) {\n      mediaType.audio = false;\n    }\n\n    if (typeof mediaType.video !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length) {\n      mediaType.video = false;\n    }\n\n    if (typeof mediaType.gif !== 'function' && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length) {\n      mediaType.gif = false;\n    }\n\n    if (!mediaType.audio && !mediaType.video && !mediaType.gif) {\n      throw 'MediaStream must have either audio or video tracks.';\n    }\n\n    if (!!mediaType.audio) {\n      recorderType = null;\n\n      if (typeof mediaType.audio === 'function') {\n        recorderType = mediaType.audio;\n      }\n\n      this.audioRecorder = new RecordRTC(mediaStream, {\n        type: 'audio',\n        bufferSize: this.bufferSize,\n        sampleRate: this.sampleRate,\n        numberOfAudioChannels: this.numberOfAudioChannels || 2,\n        disableLogs: this.disableLogs,\n        recorderType: recorderType,\n        mimeType: mimeType.audio,\n        timeSlice: this.timeSlice,\n        onTimeStamp: this.onTimeStamp\n      });\n\n      if (!mediaType.video) {\n        this.audioRecorder.startRecording();\n      }\n    }\n\n    if (!!mediaType.video) {\n      recorderType = null;\n\n      if (typeof mediaType.video === 'function') {\n        recorderType = mediaType.video;\n      }\n\n      var newStream = mediaStream;\n\n      if (isMediaRecorderCompatible() && !!mediaType.audio && typeof mediaType.audio === 'function') {\n        var videoTrack = getTracks(mediaStream, 'video')[0];\n\n        if (isFirefox) {\n          newStream = new MediaStream();\n          newStream.addTrack(videoTrack);\n\n          if (recorderType && recorderType === WhammyRecorder) {\n            // Firefox does NOT supports webp-encoding yet\n            // But Firefox do supports WebAssemblyRecorder\n            recorderType = MediaStreamRecorder;\n          }\n        } else {\n          newStream = new MediaStream();\n          newStream.addTrack(videoTrack);\n        }\n      }\n\n      this.videoRecorder = new RecordRTC(newStream, {\n        type: 'video',\n        video: this.video,\n        canvas: this.canvas,\n        frameInterval: this.frameInterval || 10,\n        disableLogs: this.disableLogs,\n        recorderType: recorderType,\n        mimeType: mimeType.video,\n        timeSlice: this.timeSlice,\n        onTimeStamp: this.onTimeStamp,\n        workerPath: this.workerPath,\n        webAssemblyPath: this.webAssemblyPath,\n        frameRate: this.frameRate,\n        // used by WebAssemblyRecorder; values: usually 30; accepts any.\n        bitrate: this.bitrate // used by WebAssemblyRecorder; values: 0 to 1000+\n\n      });\n\n      if (!mediaType.audio) {\n        this.videoRecorder.startRecording();\n      }\n    }\n\n    if (!!mediaType.audio && !!mediaType.video) {\n      var self = this;\n      var isSingleRecorder = isMediaRecorderCompatible() === true;\n\n      if (mediaType.audio instanceof StereoAudioRecorder && !!mediaType.video) {\n        isSingleRecorder = false;\n      } else if (mediaType.audio !== true && mediaType.video !== true && mediaType.audio !== mediaType.video) {\n        isSingleRecorder = false;\n      }\n\n      if (isSingleRecorder === true) {\n        self.audioRecorder = null;\n        self.videoRecorder.startRecording();\n      } else {\n        self.videoRecorder.initRecorder(function () {\n          self.audioRecorder.initRecorder(function () {\n            // Both recorders are ready to record things accurately\n            self.videoRecorder.startRecording();\n            self.audioRecorder.startRecording();\n          });\n        });\n      }\n    }\n\n    if (!!mediaType.gif) {\n      recorderType = null;\n\n      if (typeof mediaType.gif === 'function') {\n        recorderType = mediaType.gif;\n      }\n\n      this.gifRecorder = new RecordRTC(mediaStream, {\n        type: 'gif',\n        frameRate: this.frameRate || 200,\n        quality: this.quality || 10,\n        disableLogs: this.disableLogs,\n        recorderType: recorderType,\n        mimeType: mimeType.gif\n      });\n      this.gifRecorder.startRecording();\n    }\n  };\n  /**\r\n   * This method stops recording.\r\n   * @param {function} callback - Callback function is invoked when all encoders finished their jobs.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.stopRecording(function(recording){\r\n   *     var audioBlob = recording.audio;\r\n   *     var videoBlob = recording.video;\r\n   *     var gifBlob   = recording.gif;\r\n   * });\r\n   */\n\n\n  this.stopRecording = function (callback) {\n    callback = callback || function () {};\n\n    if (this.audioRecorder) {\n      this.audioRecorder.stopRecording(function (blobURL) {\n        callback(blobURL, 'audio');\n      });\n    }\n\n    if (this.videoRecorder) {\n      this.videoRecorder.stopRecording(function (blobURL) {\n        callback(blobURL, 'video');\n      });\n    }\n\n    if (this.gifRecorder) {\n      this.gifRecorder.stopRecording(function (blobURL) {\n        callback(blobURL, 'gif');\n      });\n    }\n  };\n  /**\r\n   * This method pauses recording.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.pauseRecording();\r\n   */\n\n\n  this.pauseRecording = function () {\n    if (this.audioRecorder) {\n      this.audioRecorder.pauseRecording();\n    }\n\n    if (this.videoRecorder) {\n      this.videoRecorder.pauseRecording();\n    }\n\n    if (this.gifRecorder) {\n      this.gifRecorder.pauseRecording();\n    }\n  };\n  /**\r\n   * This method resumes recording.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.resumeRecording();\r\n   */\n\n\n  this.resumeRecording = function () {\n    if (this.audioRecorder) {\n      this.audioRecorder.resumeRecording();\n    }\n\n    if (this.videoRecorder) {\n      this.videoRecorder.resumeRecording();\n    }\n\n    if (this.gifRecorder) {\n      this.gifRecorder.resumeRecording();\n    }\n  };\n  /**\r\n   * This method can be used to manually get all recorded blobs.\r\n   * @param {function} callback - All recorded blobs are passed back to the \"callback\" function.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.getBlob(function(recording){\r\n   *     var audioBlob = recording.audio;\r\n   *     var videoBlob = recording.video;\r\n   *     var gifBlob   = recording.gif;\r\n   * });\r\n   * // or\r\n   * var audioBlob = recorder.getBlob().audio;\r\n   * var videoBlob = recorder.getBlob().video;\r\n   */\n\n\n  this.getBlob = function (callback) {\n    var output = {};\n\n    if (this.audioRecorder) {\n      output.audio = this.audioRecorder.getBlob();\n    }\n\n    if (this.videoRecorder) {\n      output.video = this.videoRecorder.getBlob();\n    }\n\n    if (this.gifRecorder) {\n      output.gif = this.gifRecorder.getBlob();\n    }\n\n    if (callback) {\n      callback(output);\n    }\n\n    return output;\n  };\n  /**\r\n   * Destroy all recorder instances.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.destroy();\r\n   */\n\n\n  this.destroy = function () {\n    if (this.audioRecorder) {\n      this.audioRecorder.destroy();\n      this.audioRecorder = null;\n    }\n\n    if (this.videoRecorder) {\n      this.videoRecorder.destroy();\n      this.videoRecorder = null;\n    }\n\n    if (this.gifRecorder) {\n      this.gifRecorder.destroy();\n      this.gifRecorder = null;\n    }\n  };\n  /**\r\n   * This method can be used to manually get all recorded blobs' DataURLs.\r\n   * @param {function} callback - All recorded blobs' DataURLs are passed back to the \"callback\" function.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.getDataURL(function(recording){\r\n   *     var audioDataURL = recording.audio;\r\n   *     var videoDataURL = recording.video;\r\n   *     var gifDataURL   = recording.gif;\r\n   * });\r\n   */\n\n\n  this.getDataURL = function (callback) {\n    this.getBlob(function (blob) {\n      if (blob.audio && blob.video) {\n        getDataURL(blob.audio, function (_audioDataURL) {\n          getDataURL(blob.video, function (_videoDataURL) {\n            callback({\n              audio: _audioDataURL,\n              video: _videoDataURL\n            });\n          });\n        });\n      } else if (blob.audio) {\n        getDataURL(blob.audio, function (_audioDataURL) {\n          callback({\n            audio: _audioDataURL\n          });\n        });\n      } else if (blob.video) {\n        getDataURL(blob.video, function (_videoDataURL) {\n          callback({\n            video: _videoDataURL\n          });\n        });\n      }\n    });\n\n    function getDataURL(blob, callback00) {\n      if (typeof Worker !== 'undefined') {\n        var webWorker = processInWebWorker(function readFile(_blob) {\n          postMessage(new FileReaderSync().readAsDataURL(_blob));\n        });\n\n        webWorker.onmessage = function (event) {\n          callback00(event.data);\n        };\n\n        webWorker.postMessage(blob);\n      } else {\n        var reader = new FileReader();\n        reader.readAsDataURL(blob);\n\n        reader.onload = function (event) {\n          callback00(event.target.result);\n        };\n      }\n    }\n\n    function processInWebWorker(_function) {\n      var blob = URL.createObjectURL(new Blob([_function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'], {\n        type: 'application/javascript'\n      }));\n      var worker = new Worker(blob);\n      var url;\n\n      if (typeof URL !== 'undefined') {\n        url = URL;\n      } else if (typeof webkitURL !== 'undefined') {\n        url = webkitURL;\n      } else {\n        throw 'Neither URL nor webkitURL detected.';\n      }\n\n      url.revokeObjectURL(blob);\n      return worker;\n    }\n  };\n  /**\r\n   * This method can be used to ask {@link MRecordRTC} to write all recorded blobs into IndexedDB storage.\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.writeToDisk();\r\n   */\n\n\n  this.writeToDisk = function () {\n    RecordRTC.writeToDisk({\n      audio: this.audioRecorder,\n      video: this.videoRecorder,\n      gif: this.gifRecorder\n    });\n  };\n  /**\r\n   * This method can be used to invoke a save-as dialog for all recorded blobs.\r\n   * @param {object} args - {audio: 'audio-name', video: 'video-name', gif: 'gif-name'}\r\n   * @method\r\n   * @memberof MRecordRTC\r\n   * @example\r\n   * recorder.save({\r\n   *     audio: 'audio-file-name',\r\n   *     video: 'video-file-name',\r\n   *     gif  : 'gif-file-name'\r\n   * });\r\n   */\n\n\n  this.save = function (args) {\n    args = args || {\n      audio: true,\n      video: true,\n      gif: true\n    };\n\n    if (!!args.audio && this.audioRecorder) {\n      this.audioRecorder.save(typeof args.audio === 'string' ? args.audio : '');\n    }\n\n    if (!!args.video && this.videoRecorder) {\n      this.videoRecorder.save(typeof args.video === 'string' ? args.video : '');\n    }\n\n    if (!!args.gif && this.gifRecorder) {\n      this.gifRecorder.save(typeof args.gif === 'string' ? args.gif : '');\n    }\n  };\n}\n/**\r\n * This method can be used to get all recorded blobs from IndexedDB storage.\r\n * @param {string} type - 'all' or 'audio' or 'video' or 'gif'\r\n * @param {function} callback - Callback function to get all stored blobs.\r\n * @method\r\n * @memberof MRecordRTC\r\n * @example\r\n * MRecordRTC.getFromDisk('all', function(dataURL, type){\r\n *     if(type === 'audio') { }\r\n *     if(type === 'video') { }\r\n *     if(type === 'gif')   { }\r\n * });\r\n */\n\n\nMRecordRTC.getFromDisk = RecordRTC.getFromDisk;\n/**\r\n * This method can be used to store recorded blobs into IndexedDB storage.\r\n * @param {object} options - {audio: Blob, video: Blob, gif: Blob}\r\n * @method\r\n * @memberof MRecordRTC\r\n * @example\r\n * MRecordRTC.writeToDisk({\r\n *     audio: audioBlob,\r\n *     video: videoBlob,\r\n *     gif  : gifBlob\r\n * });\r\n */\n\nMRecordRTC.writeToDisk = RecordRTC.writeToDisk;\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.MRecordRTC = MRecordRTC;\n}\n\nvar browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';\n\n(function (that) {\n  if (!that) {\n    return;\n  }\n\n  if (typeof window !== 'undefined') {\n    return;\n  }\n\n  if (typeof global === 'undefined') {\n    return;\n  }\n\n  global.navigator = {\n    userAgent: browserFakeUserAgent,\n    getUserMedia: function getUserMedia() {}\n  };\n\n  if (!global.console) {\n    global.console = {};\n  }\n\n  if (typeof global.console.log === 'undefined' || typeof global.console.error === 'undefined') {\n    global.console.error = global.console.log = global.console.log || function () {\n      console.log(arguments);\n    };\n  }\n\n  if (typeof document === 'undefined') {\n    /*global document:true */\n    that.document = {\n      documentElement: {\n        appendChild: function appendChild() {\n          return '';\n        }\n      }\n    };\n\n    document.createElement = document.captureStream = document.mozCaptureStream = function () {\n      var obj = {\n        getContext: function getContext() {\n          return obj;\n        },\n        play: function play() {},\n        pause: function pause() {},\n        drawImage: function drawImage() {},\n        toDataURL: function toDataURL() {\n          return '';\n        },\n        style: {}\n      };\n      return obj;\n    };\n\n    that.HTMLVideoElement = function () {};\n  }\n\n  if (typeof location === 'undefined') {\n    /*global location:true */\n    that.location = {\n      protocol: 'file:',\n      href: '',\n      hash: ''\n    };\n  }\n\n  if (typeof screen === 'undefined') {\n    /*global screen:true */\n    that.screen = {\n      width: 0,\n      height: 0\n    };\n  }\n\n  if (typeof URL === 'undefined') {\n    /*global screen:true */\n    that.URL = {\n      createObjectURL: function createObjectURL() {\n        return '';\n      },\n      revokeObjectURL: function revokeObjectURL() {\n        return '';\n      }\n    };\n  }\n  /*global window:true */\n\n\n  that.window = global;\n})(typeof global !== 'undefined' ? global : null); // _____________________________\n// Cross-Browser-Declarations.js\n// animation-frame used in WebM recording\n\n/*jshint -W079 */\n\n\nvar requestAnimationFrame = window.requestAnimationFrame;\n\nif (typeof requestAnimationFrame === 'undefined') {\n  if (typeof webkitRequestAnimationFrame !== 'undefined') {\n    /*global requestAnimationFrame:true */\n    requestAnimationFrame = webkitRequestAnimationFrame;\n  } else if (typeof mozRequestAnimationFrame !== 'undefined') {\n    /*global requestAnimationFrame:true */\n    requestAnimationFrame = mozRequestAnimationFrame;\n  } else if (typeof msRequestAnimationFrame !== 'undefined') {\n    /*global requestAnimationFrame:true */\n    requestAnimationFrame = msRequestAnimationFrame;\n  } else if (typeof requestAnimationFrame === 'undefined') {\n    // via: https://gist.github.com/paulirish/1579671\n    var lastTime = 0;\n    /*global requestAnimationFrame:true */\n\n    requestAnimationFrame = function requestAnimationFrame(callback, element) {\n      var currTime = new Date().getTime();\n      var timeToCall = Math.max(0, 16 - (currTime - lastTime));\n      var id = setTimeout(function () {\n        callback(currTime + timeToCall);\n      }, timeToCall);\n      lastTime = currTime + timeToCall;\n      return id;\n    };\n  }\n}\n/*jshint -W079 */\n\n\nvar cancelAnimationFrame = window.cancelAnimationFrame;\n\nif (typeof cancelAnimationFrame === 'undefined') {\n  if (typeof webkitCancelAnimationFrame !== 'undefined') {\n    /*global cancelAnimationFrame:true */\n    cancelAnimationFrame = webkitCancelAnimationFrame;\n  } else if (typeof mozCancelAnimationFrame !== 'undefined') {\n    /*global cancelAnimationFrame:true */\n    cancelAnimationFrame = mozCancelAnimationFrame;\n  } else if (typeof msCancelAnimationFrame !== 'undefined') {\n    /*global cancelAnimationFrame:true */\n    cancelAnimationFrame = msCancelAnimationFrame;\n  } else if (typeof cancelAnimationFrame === 'undefined') {\n    /*global cancelAnimationFrame:true */\n    cancelAnimationFrame = function cancelAnimationFrame(id) {\n      clearTimeout(id);\n    };\n  }\n} // WebAudio API representer\n\n\nvar AudioContext = window.AudioContext;\n\nif (typeof AudioContext === 'undefined') {\n  if (typeof webkitAudioContext !== 'undefined') {\n    /*global AudioContext:true */\n    AudioContext = webkitAudioContext;\n  }\n\n  if (typeof mozAudioContext !== 'undefined') {\n    /*global AudioContext:true */\n    AudioContext = mozAudioContext;\n  }\n}\n/*jshint -W079 */\n\n\nvar URL = window.URL;\n\nif (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {\n  /*global URL:true */\n  URL = webkitURL;\n}\n\nif (typeof navigator !== 'undefined' && typeof navigator.getUserMedia === 'undefined') {\n  // maybe window.navigator?\n  if (typeof navigator.webkitGetUserMedia !== 'undefined') {\n    navigator.getUserMedia = navigator.webkitGetUserMedia;\n  }\n\n  if (typeof navigator.mozGetUserMedia !== 'undefined') {\n    navigator.getUserMedia = navigator.mozGetUserMedia;\n  }\n}\n\nvar isEdge = navigator.userAgent.indexOf('Edge') !== -1 && (!!navigator.msSaveBlob || !!navigator.msSaveOrOpenBlob);\nvar isOpera = !!window.opera || navigator.userAgent.indexOf('OPR/') !== -1;\nvar isFirefox = navigator.userAgent.toLowerCase().indexOf('firefox') > -1 && 'netscape' in window && / rv:/.test(navigator.userAgent);\nvar isChrome = !isOpera && !isEdge && !!navigator.webkitGetUserMedia || isElectron() || navigator.userAgent.toLowerCase().indexOf('chrome/') !== -1;\nvar isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);\n\nif (isSafari && !isChrome && navigator.userAgent.indexOf('CriOS') !== -1) {\n  isSafari = false;\n  isChrome = true;\n}\n\nvar MediaStream = window.MediaStream;\n\nif (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {\n  MediaStream = webkitMediaStream;\n}\n/*global MediaStream:true */\n\n\nif (typeof MediaStream !== 'undefined') {\n  // override \"stop\" method for all browsers\n  if (typeof MediaStream.prototype.stop === 'undefined') {\n    MediaStream.prototype.stop = function () {\n      this.getTracks().forEach(function (track) {\n        track.stop();\n      });\n    };\n  }\n} // below function via: http://goo.gl/B3ae8c\n\n/**\r\n * Return human-readable file size.\r\n * @param {number} bytes - Pass bytes and get formatted string.\r\n * @returns {string} - formatted string\r\n * @example\r\n * bytesToSize(1024*1024*5) === '5 GB'\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nfunction bytesToSize(bytes) {\n  var k = 1000;\n  var sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\n\n  if (bytes === 0) {\n    return '0 Bytes';\n  }\n\n  var i = parseInt(Math.floor(Math.log(bytes) / Math.log(k)), 10);\n  return (bytes / Math.pow(k, i)).toPrecision(3) + ' ' + sizes[i];\n}\n/**\r\n * @param {Blob} file - File or Blob object. This parameter is required.\r\n * @param {string} fileName - Optional file name e.g. \"Recorded-Video.webm\"\r\n * @example\r\n * invokeSaveAsDialog(blob or file, [optional] fileName);\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nfunction invokeSaveAsDialog(file, fileName) {\n  if (!file) {\n    throw 'Blob object is required.';\n  }\n\n  if (!file.type) {\n    try {\n      file.type = 'video/webm';\n    } catch (e) {}\n  }\n\n  var fileExtension = (file.type || 'video/webm').split('/')[1];\n\n  if (fileExtension.indexOf(';') !== -1) {\n    // extended mimetype, e.g. 'video/webm;codecs=vp8,opus'\n    fileExtension = fileExtension.split(';')[0];\n  }\n\n  if (fileName && fileName.indexOf('.') !== -1) {\n    var splitted = fileName.split('.');\n    fileName = splitted[0];\n    fileExtension = splitted[1];\n  }\n\n  var fileFullName = (fileName || Math.round(Math.random() * 9999999999) + 888888888) + '.' + fileExtension;\n\n  if (typeof navigator.msSaveOrOpenBlob !== 'undefined') {\n    return navigator.msSaveOrOpenBlob(file, fileFullName);\n  } else if (typeof navigator.msSaveBlob !== 'undefined') {\n    return navigator.msSaveBlob(file, fileFullName);\n  }\n\n  var hyperlink = document.createElement('a');\n  hyperlink.href = URL.createObjectURL(file);\n  hyperlink.download = fileFullName;\n  hyperlink.style = 'display:none;opacity:0;color:transparent;';\n  (document.body || document.documentElement).appendChild(hyperlink);\n\n  if (typeof hyperlink.click === 'function') {\n    hyperlink.click();\n  } else {\n    hyperlink.target = '_blank';\n    hyperlink.dispatchEvent(new MouseEvent('click', {\n      view: window,\n      bubbles: true,\n      cancelable: true\n    }));\n  }\n\n  URL.revokeObjectURL(hyperlink.href);\n}\n/**\r\n * from: https://github.com/cheton/is-electron/blob/master/index.js\r\n **/\n\n\nfunction isElectron() {\n  // Renderer process\n  if (typeof window !== 'undefined' && _typeof(window.process) === 'object' && window.process.type === 'renderer') {\n    return true;\n  } // Main process\n\n\n  if (typeof process !== 'undefined' && _typeof(process.versions) === 'object' && !!process.versions.electron) {\n    return true;\n  } // Detect the user agent when the `nodeIntegration` option is set to true\n\n\n  if ((typeof navigator === \"undefined\" ? \"undefined\" : _typeof(navigator)) === 'object' && typeof navigator.userAgent === 'string' && navigator.userAgent.indexOf('Electron') >= 0) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction getTracks(stream, kind) {\n  if (!stream || !stream.getTracks) {\n    return [];\n  }\n\n  return stream.getTracks().filter(function (t) {\n    return t.kind === (kind || 'audio');\n  });\n}\n\nfunction setSrcObject(stream, element) {\n  if ('srcObject' in element) {\n    element.srcObject = stream;\n  } else if ('mozSrcObject' in element) {\n    element.mozSrcObject = stream;\n  } else {\n    element.srcObject = stream;\n  }\n}\n/**\r\n * @param {Blob} file - File or Blob object.\r\n * @param {function} callback - Callback function.\r\n * @example\r\n * getSeekableBlob(blob or file, callback);\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nfunction getSeekableBlob(inputBlob, callback) {\n  // EBML.js copyrights goes to: https://github.com/legokichi/ts-ebml\n  if (typeof EBML === 'undefined') {\n    throw new Error('Please link: https://www.webrtc-experiment.com/EBML.js');\n  }\n\n  var reader = new EBML.Reader();\n  var decoder = new EBML.Decoder();\n  var tools = EBML.tools;\n  var fileReader = new FileReader();\n\n  fileReader.onload = function (e) {\n    var ebmlElms = decoder.decode(this.result);\n    ebmlElms.forEach(function (element) {\n      reader.read(element);\n    });\n    reader.stop();\n    var refinedMetadataBuf = tools.makeMetadataSeekable(reader.metadatas, reader.duration, reader.cues);\n    var body = this.result.slice(reader.metadataSize);\n    var newBlob = new Blob([refinedMetadataBuf, body], {\n      type: 'video/webm'\n    });\n    callback(newBlob);\n  };\n\n  fileReader.readAsArrayBuffer(inputBlob);\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.invokeSaveAsDialog = invokeSaveAsDialog;\n  RecordRTC.getTracks = getTracks;\n  RecordRTC.getSeekableBlob = getSeekableBlob;\n  RecordRTC.bytesToSize = bytesToSize;\n  RecordRTC.isElectron = isElectron;\n} // __________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129\n// Storage.js\n\n/**\r\n * Storage is a standalone object used by {@link RecordRTC} to store reusable objects e.g. \"new AudioContext\".\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @example\r\n * Storage.AudioContext === webkitAudioContext\r\n * @property {webkitAudioContext} AudioContext - Keeps a reference to AudioContext object.\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nvar Storage = {};\n\nif (typeof AudioContext !== 'undefined') {\n  Storage.AudioContext = AudioContext;\n} else if (typeof webkitAudioContext !== 'undefined') {\n  Storage.AudioContext = webkitAudioContext;\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.Storage = Storage;\n}\n\nfunction isMediaRecorderCompatible() {\n  if (isFirefox || isSafari || isEdge) {\n    return true;\n  }\n\n  var nVer = navigator.appVersion;\n  var nAgt = navigator.userAgent;\n  var fullVersion = '' + parseFloat(navigator.appVersion);\n  var majorVersion = parseInt(navigator.appVersion, 10);\n  var nameOffset, verOffset, ix;\n\n  if (isChrome || isOpera) {\n    verOffset = nAgt.indexOf('Chrome');\n    fullVersion = nAgt.substring(verOffset + 7);\n  } // trim the fullVersion string at semicolon/space if present\n\n\n  if ((ix = fullVersion.indexOf(';')) !== -1) {\n    fullVersion = fullVersion.substring(0, ix);\n  }\n\n  if ((ix = fullVersion.indexOf(' ')) !== -1) {\n    fullVersion = fullVersion.substring(0, ix);\n  }\n\n  majorVersion = parseInt('' + fullVersion, 10);\n\n  if (isNaN(majorVersion)) {\n    fullVersion = '' + parseFloat(navigator.appVersion);\n    majorVersion = parseInt(navigator.appVersion, 10);\n  }\n\n  return majorVersion >= 49;\n} // ______________________\n// MediaStreamRecorder.js\n\n/**\r\n * MediaStreamRecorder is an abstraction layer for {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}. It is used by {@link RecordRTC} to record MediaStream(s) in both Chrome and Firefox.\r\n * @summary Runs top over {@link https://w3c.github.io/mediacapture-record/MediaRecorder.html|MediaRecorder API}.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://github.com/muaz-khan|Muaz Khan}\r\n * @typedef MediaStreamRecorder\r\n * @class\r\n * @example\r\n * var config = {\r\n *     mimeType: 'video/webm', // vp8, vp9, h264, mkv, opus/vorbis\r\n *     audioBitsPerSecond : 256 * 8 * 1024,\r\n *     videoBitsPerSecond : 256 * 8 * 1024,\r\n *     bitsPerSecond: 256 * 8 * 1024,  // if this is provided, skip above two\r\n *     checkForInactiveTracks: true,\r\n *     timeSlice: 1000, // concatenate intervals based blobs\r\n *     ondataavailable: function() {} // get intervals based blobs\r\n * }\r\n * var recorder = new MediaStreamRecorder(mediaStream, config);\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n *\r\n *     // or\r\n *     var blob = recorder.blob;\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {disableLogs:true, initCallback: function, mimeType: \"video/webm\", timeSlice: 1000}\r\n * @throws Will throw an error if first argument \"MediaStream\" is missing. Also throws error if \"MediaRecorder API\" are not supported by the browser.\r\n */\n\n\nfunction MediaStreamRecorder(mediaStream, config) {\n  var self = this;\n\n  if (typeof mediaStream === 'undefined') {\n    throw 'First argument \"MediaStream\" is required.';\n  }\n\n  if (typeof MediaRecorder === 'undefined') {\n    throw 'Your browser does not support the Media Recorder API. Please try other modules e.g. WhammyRecorder or StereoAudioRecorder.';\n  }\n\n  config = config || {\n    // bitsPerSecond: 256 * 8 * 1024,\n    mimeType: 'video/webm'\n  };\n\n  if (config.type === 'audio') {\n    if (getTracks(mediaStream, 'video').length && getTracks(mediaStream, 'audio').length) {\n      var stream;\n\n      if (!!navigator.mozGetUserMedia) {\n        stream = new MediaStream();\n        stream.addTrack(getTracks(mediaStream, 'audio')[0]);\n      } else {\n        // webkitMediaStream\n        stream = new MediaStream(getTracks(mediaStream, 'audio'));\n      }\n\n      mediaStream = stream;\n    }\n\n    if (!config.mimeType || config.mimeType.toString().toLowerCase().indexOf('audio') === -1) {\n      config.mimeType = isChrome ? 'audio/webm' : 'audio/ogg';\n    }\n\n    if (config.mimeType && config.mimeType.toString().toLowerCase() !== 'audio/ogg' && !!navigator.mozGetUserMedia) {\n      // forcing better codecs on Firefox (via #166)\n      config.mimeType = 'audio/ogg';\n    }\n  }\n\n  var arrayOfBlobs = [];\n  /**\r\n   * This method returns array of blobs. Use only with \"timeSlice\". Its useful to preview recording anytime, without using the \"stop\" method.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * var arrayOfBlobs = recorder.getArrayOfBlobs();\r\n   * @returns {Array} Returns array of recorded blobs.\r\n   */\n\n  this.getArrayOfBlobs = function () {\n    return arrayOfBlobs;\n  };\n  /**\r\n   * This method records MediaStream.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n\n  this.record = function () {\n    // set defaults\n    self.blob = null;\n    self.clearRecordedData();\n    self.timestamps = [];\n    allStates = [];\n    arrayOfBlobs = [];\n    var recorderHints = config;\n\n    if (!config.disableLogs) {\n      console.log('Passing following config over MediaRecorder API.', recorderHints);\n    }\n\n    if (mediaRecorder) {\n      // mandatory to make sure Firefox doesn't fails to record streams 3-4 times without reloading the page.\n      mediaRecorder = null;\n    }\n\n    if (isChrome && !isMediaRecorderCompatible()) {\n      // to support video-only recording on stable\n      recorderHints = 'video/vp8';\n    }\n\n    if (typeof MediaRecorder.isTypeSupported === 'function' && recorderHints.mimeType) {\n      if (!MediaRecorder.isTypeSupported(recorderHints.mimeType)) {\n        if (!config.disableLogs) {\n          console.warn('MediaRecorder API seems unable to record mimeType:', recorderHints.mimeType);\n        }\n\n        recorderHints.mimeType = config.type === 'audio' ? 'audio/webm' : 'video/webm';\n      }\n    } // using MediaRecorder API here\n\n\n    try {\n      mediaRecorder = new MediaRecorder(mediaStream, recorderHints); // reset\n\n      config.mimeType = recorderHints.mimeType;\n    } catch (e) {\n      // chrome-based fallback\n      mediaRecorder = new MediaRecorder(mediaStream);\n    } // old hack?\n\n\n    if (recorderHints.mimeType && !MediaRecorder.isTypeSupported && 'canRecordMimeType' in mediaRecorder && mediaRecorder.canRecordMimeType(recorderHints.mimeType) === false) {\n      if (!config.disableLogs) {\n        console.warn('MediaRecorder API seems unable to record mimeType:', recorderHints.mimeType);\n      }\n    } // Dispatching OnDataAvailable Handler\n\n\n    mediaRecorder.ondataavailable = function (e) {\n      if (e.data) {\n        allStates.push('ondataavailable: ' + bytesToSize(e.data.size));\n      }\n\n      if (typeof config.timeSlice === 'number') {\n        if (e.data && e.data.size) {\n          arrayOfBlobs.push(e.data);\n          updateTimeStamp();\n\n          if (typeof config.ondataavailable === 'function') {\n            // intervals based blobs\n            var blob = config.getNativeBlob ? e.data : new Blob([e.data], {\n              type: getMimeType(recorderHints)\n            });\n            config.ondataavailable(blob);\n          }\n        }\n\n        return;\n      }\n\n      if (!e.data || !e.data.size || e.data.size < 100 || self.blob) {\n        // make sure that stopRecording always getting fired\n        // even if there is invalid data\n        if (self.recordingCallback) {\n          self.recordingCallback(new Blob([], {\n            type: getMimeType(recorderHints)\n          }));\n          self.recordingCallback = null;\n        }\n\n        return;\n      }\n\n      self.blob = config.getNativeBlob ? e.data : new Blob([e.data], {\n        type: getMimeType(recorderHints)\n      });\n\n      if (self.recordingCallback) {\n        self.recordingCallback(self.blob);\n        self.recordingCallback = null;\n      }\n    };\n\n    mediaRecorder.onstart = function () {\n      allStates.push('started');\n    };\n\n    mediaRecorder.onpause = function () {\n      allStates.push('paused');\n    };\n\n    mediaRecorder.onresume = function () {\n      allStates.push('resumed');\n    };\n\n    mediaRecorder.onstop = function () {\n      allStates.push('stopped');\n    };\n\n    mediaRecorder.onerror = function (error) {\n      if (!error) {\n        return;\n      }\n\n      if (!error.name) {\n        error.name = 'UnknownError';\n      }\n\n      allStates.push('error: ' + error);\n\n      if (!config.disableLogs) {\n        // via: https://w3c.github.io/mediacapture-record/MediaRecorder.html#exception-summary\n        if (error.name.toString().toLowerCase().indexOf('invalidstate') !== -1) {\n          console.error('The MediaRecorder is not in a state in which the proposed operation is allowed to be executed.', error);\n        } else if (error.name.toString().toLowerCase().indexOf('notsupported') !== -1) {\n          console.error('MIME type (', recorderHints.mimeType, ') is not supported.', error);\n        } else if (error.name.toString().toLowerCase().indexOf('security') !== -1) {\n          console.error('MediaRecorder security error', error);\n        } // older code below\n        else if (error.name === 'OutOfMemory') {\n            console.error('The UA has exhaused the available memory. User agents SHOULD provide as much additional information as possible in the message attribute.', error);\n          } else if (error.name === 'IllegalStreamModification') {\n            console.error('A modification to the stream has occurred that makes it impossible to continue recording. An example would be the addition of a Track while recording is occurring. User agents SHOULD provide as much additional information as possible in the message attribute.', error);\n          } else if (error.name === 'OtherRecordingError') {\n            console.error('Used for an fatal error other than those listed above. User agents SHOULD provide as much additional information as possible in the message attribute.', error);\n          } else if (error.name === 'GenericError') {\n            console.error('The UA cannot provide the codec or recording option that has been requested.', error);\n          } else {\n            console.error('MediaRecorder Error', error);\n          }\n      }\n\n      (function (looper) {\n        if (!self.manuallyStopped && mediaRecorder && mediaRecorder.state === 'inactive') {\n          delete config.timeslice; // 10 minutes, enough?\n\n          mediaRecorder.start(10 * 60 * 1000);\n          return;\n        }\n\n        setTimeout(looper, 1000);\n      })();\n\n      if (mediaRecorder.state !== 'inactive' && mediaRecorder.state !== 'stopped') {\n        mediaRecorder.stop();\n      }\n    };\n\n    if (typeof config.timeSlice === 'number') {\n      updateTimeStamp();\n      mediaRecorder.start(config.timeSlice);\n    } else {\n      // default is 60 minutes; enough?\n      // use config => {timeSlice: 1000} otherwise\n      mediaRecorder.start(3.6e+6);\n    }\n\n    if (config.initCallback) {\n      config.initCallback(); // old code\n    }\n  };\n  /**\r\n   * @property {Array} timestamps - Array of time stamps\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * console.log(recorder.timestamps);\r\n   */\n\n\n  this.timestamps = [];\n\n  function updateTimeStamp() {\n    self.timestamps.push(new Date().getTime());\n\n    if (typeof config.onTimeStamp === 'function') {\n      config.onTimeStamp(self.timestamps[self.timestamps.length - 1], self.timestamps);\n    }\n  }\n\n  function getMimeType(secondObject) {\n    if (mediaRecorder && mediaRecorder.mimeType) {\n      return mediaRecorder.mimeType;\n    }\n\n    return secondObject.mimeType || 'video/webm';\n  }\n  /**\r\n   * This method stops recording MediaStream.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n\n  this.stop = function (callback) {\n    callback = callback || function () {};\n\n    self.manuallyStopped = true; // used inside the mediaRecorder.onerror\n\n    if (!mediaRecorder) {\n      return;\n    }\n\n    this.recordingCallback = callback;\n\n    if (mediaRecorder.state === 'recording') {\n      mediaRecorder.stop();\n    }\n\n    if (typeof config.timeSlice === 'number') {\n      setTimeout(function () {\n        self.blob = new Blob(arrayOfBlobs, {\n          type: getMimeType(config)\n        });\n        self.recordingCallback(self.blob);\n      }, 100);\n    }\n  };\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n\n  this.pause = function () {\n    if (!mediaRecorder) {\n      return;\n    }\n\n    if (mediaRecorder.state === 'recording') {\n      mediaRecorder.pause();\n    }\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    if (!mediaRecorder) {\n      return;\n    }\n\n    if (mediaRecorder.state === 'paused') {\n      mediaRecorder.resume();\n    }\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    if (mediaRecorder && mediaRecorder.state === 'recording') {\n      self.stop(clearRecordedDataCB);\n    }\n\n    clearRecordedDataCB();\n  };\n\n  function clearRecordedDataCB() {\n    arrayOfBlobs = [];\n    mediaRecorder = null;\n    self.timestamps = [];\n  } // Reference to \"MediaRecorder\" object\n\n\n  var mediaRecorder;\n  /**\r\n   * Access to native MediaRecorder API\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @instance\r\n   * @example\r\n   * var internal = recorder.getInternalRecorder();\r\n   * internal.ondataavailable = function() {}; // override\r\n   * internal.stream, internal.onpause, internal.onstop, etc.\r\n   * @returns {Object} Returns internal recording object.\r\n   */\n\n  this.getInternalRecorder = function () {\n    return mediaRecorder;\n  };\n\n  function isMediaStreamActive() {\n    if ('active' in mediaStream) {\n      if (!mediaStream.active) {\n        return false;\n      }\n    } else if ('ended' in mediaStream) {\n      // old hack\n      if (mediaStream.ended) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n  /**\r\n   * @property {Blob} blob - Recorded data as \"Blob\" object.\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * recorder.stop(function() {\r\n   *     var blob = recorder.blob;\r\n   * });\r\n   */\n\n\n  this.blob = null;\n  /**\r\n   * Get MediaRecorder readonly state.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * var state = recorder.getState();\r\n   * @returns {String} Returns recording state.\r\n   */\n\n  this.getState = function () {\n    if (!mediaRecorder) {\n      return 'inactive';\n    }\n\n    return mediaRecorder.state || 'inactive';\n  }; // list of all recording states\n\n\n  var allStates = [];\n  /**\r\n   * Get MediaRecorder all recording states.\r\n   * @method\r\n   * @memberof MediaStreamRecorder\r\n   * @example\r\n   * var state = recorder.getAllStates();\r\n   * @returns {Array} Returns all recording states\r\n   */\n\n  this.getAllStates = function () {\n    return allStates;\n  }; // if any Track within the MediaStream is muted or not enabled at any time, \n  // the browser will only record black frames \n  // or silence since that is the content produced by the Track\n  // so we need to stopRecording as soon as any single track ends.\n\n\n  if (typeof config.checkForInactiveTracks === 'undefined') {\n    config.checkForInactiveTracks = false; // disable to minimize CPU usage\n  }\n\n  var self = this; // this method checks if media stream is stopped\n  // or if any track is ended.\n\n  (function looper() {\n    if (!mediaRecorder || config.checkForInactiveTracks === false) {\n      return;\n    }\n\n    if (isMediaStreamActive() === false) {\n      if (!config.disableLogs) {\n        console.log('MediaStream seems stopped.');\n      }\n\n      self.stop();\n      return;\n    }\n\n    setTimeout(looper, 1000); // check every second\n  })(); // for debugging\n\n\n  this.name = 'MediaStreamRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.MediaStreamRecorder = MediaStreamRecorder;\n} // source code from: http://typedarray.org/wp-content/projects/WebAudioRecorder/script.js\n// https://github.com/mattdiamond/Recorderjs#license-mit\n// ______________________\n// StereoAudioRecorder.js\n\n/**\r\n * StereoAudioRecorder is a standalone class used by {@link RecordRTC} to bring \"stereo\" audio-recording in chrome.\r\n * @summary JavaScript standalone object for stereo audio recording.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef StereoAudioRecorder\r\n * @class\r\n * @example\r\n * var recorder = new StereoAudioRecorder(MediaStream, {\r\n *     sampleRate: 44100,\r\n *     bufferSize: 4096\r\n * });\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {sampleRate: 44100, bufferSize: 4096, numberOfAudioChannels: 1, etc.}\r\n */\n\n\nfunction StereoAudioRecorder(mediaStream, config) {\n  if (!getTracks(mediaStream, 'audio').length) {\n    throw 'Your stream has no audio tracks.';\n  }\n\n  config = config || {};\n  var self = this; // variables\n\n  var leftchannel = [];\n  var rightchannel = [];\n  var recording = false;\n  var recordingLength = 0;\n  var jsAudioNode;\n  var numberOfAudioChannels = 2;\n  /**\r\n   * Set sample rates such as 8K or 16K. Reference: http://stackoverflow.com/a/28977136/552182\r\n   * @property {number} desiredSampRate - Desired Bits per sample * 1000\r\n   * @memberof StereoAudioRecorder\r\n   * @instance\r\n   * @example\r\n   * var recorder = StereoAudioRecorder(mediaStream, {\r\n   *   desiredSampRate: 16 * 1000 // bits-per-sample * 1000\r\n   * });\r\n   */\n\n  var desiredSampRate = config.desiredSampRate; // backward compatibility\n\n  if (config.leftChannel === true) {\n    numberOfAudioChannels = 1;\n  }\n\n  if (config.numberOfAudioChannels === 1) {\n    numberOfAudioChannels = 1;\n  }\n\n  if (!numberOfAudioChannels || numberOfAudioChannels < 1) {\n    numberOfAudioChannels = 2;\n  }\n\n  if (!config.disableLogs) {\n    console.log('StereoAudioRecorder is set to record number of channels: ' + numberOfAudioChannels);\n  } // if any Track within the MediaStream is muted or not enabled at any time, \n  // the browser will only record black frames \n  // or silence since that is the content produced by the Track\n  // so we need to stopRecording as soon as any single track ends.\n\n\n  if (typeof config.checkForInactiveTracks === 'undefined') {\n    config.checkForInactiveTracks = true;\n  }\n\n  function isMediaStreamActive() {\n    if (config.checkForInactiveTracks === false) {\n      // always return \"true\"\n      return true;\n    }\n\n    if ('active' in mediaStream) {\n      if (!mediaStream.active) {\n        return false;\n      }\n    } else if ('ended' in mediaStream) {\n      // old hack\n      if (mediaStream.ended) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n  /**\r\n   * This method records MediaStream.\r\n   * @method\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n\n  this.record = function () {\n    if (isMediaStreamActive() === false) {\n      throw 'Please make sure MediaStream is active.';\n    }\n\n    resetVariables();\n    isAudioProcessStarted = isPaused = false;\n    recording = true;\n\n    if (typeof config.timeSlice !== 'undefined') {\n      looper();\n    }\n  };\n\n  function mergeLeftRightBuffers(config, callback) {\n    function mergeAudioBuffers(config, cb) {\n      var numberOfAudioChannels = config.numberOfAudioChannels; // todo: \"slice(0)\" --- is it causes loop? Should be removed?\n\n      var leftBuffers = config.leftBuffers.slice(0);\n      var rightBuffers = config.rightBuffers.slice(0);\n      var sampleRate = config.sampleRate;\n      var internalInterleavedLength = config.internalInterleavedLength;\n      var desiredSampRate = config.desiredSampRate;\n\n      if (numberOfAudioChannels === 2) {\n        leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);\n        rightBuffers = mergeBuffers(rightBuffers, internalInterleavedLength);\n\n        if (desiredSampRate) {\n          leftBuffers = interpolateArray(leftBuffers, desiredSampRate, sampleRate);\n          rightBuffers = interpolateArray(rightBuffers, desiredSampRate, sampleRate);\n        }\n      }\n\n      if (numberOfAudioChannels === 1) {\n        leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength);\n\n        if (desiredSampRate) {\n          leftBuffers = interpolateArray(leftBuffers, desiredSampRate, sampleRate);\n        }\n      } // set sample rate as desired sample rate\n\n\n      if (desiredSampRate) {\n        sampleRate = desiredSampRate;\n      } // for changing the sampling rate, reference:\n      // http://stackoverflow.com/a/28977136/552182\n\n\n      function interpolateArray(data, newSampleRate, oldSampleRate) {\n        var fitCount = Math.round(data.length * (newSampleRate / oldSampleRate));\n        var newData = [];\n        var springFactor = Number((data.length - 1) / (fitCount - 1));\n        newData[0] = data[0];\n\n        for (var i = 1; i < fitCount - 1; i++) {\n          var tmp = i * springFactor;\n          var before = Number(Math.floor(tmp)).toFixed();\n          var after = Number(Math.ceil(tmp)).toFixed();\n          var atPoint = tmp - before;\n          newData[i] = linearInterpolate(data[before], data[after], atPoint);\n        }\n\n        newData[fitCount - 1] = data[data.length - 1];\n        return newData;\n      }\n\n      function linearInterpolate(before, after, atPoint) {\n        return before + (after - before) * atPoint;\n      }\n\n      function mergeBuffers(channelBuffer, rLength) {\n        var result = new Float64Array(rLength);\n        var offset = 0;\n        var lng = channelBuffer.length;\n\n        for (var i = 0; i < lng; i++) {\n          var buffer = channelBuffer[i];\n          result.set(buffer, offset);\n          offset += buffer.length;\n        }\n\n        return result;\n      }\n\n      function interleave(leftChannel, rightChannel) {\n        var length = leftChannel.length + rightChannel.length;\n        var result = new Float64Array(length);\n        var inputIndex = 0;\n\n        for (var index = 0; index < length;) {\n          result[index++] = leftChannel[inputIndex];\n          result[index++] = rightChannel[inputIndex];\n          inputIndex++;\n        }\n\n        return result;\n      }\n\n      function writeUTFBytes(view, offset, string) {\n        var lng = string.length;\n\n        for (var i = 0; i < lng; i++) {\n          view.setUint8(offset + i, string.charCodeAt(i));\n        }\n      } // interleave both channels together\n\n\n      var interleaved;\n\n      if (numberOfAudioChannels === 2) {\n        interleaved = interleave(leftBuffers, rightBuffers);\n      }\n\n      if (numberOfAudioChannels === 1) {\n        interleaved = leftBuffers;\n      }\n\n      var interleavedLength = interleaved.length; // create wav file\n\n      var resultingBufferLength = 44 + interleavedLength * 2;\n      var buffer = new ArrayBuffer(resultingBufferLength);\n      var view = new DataView(buffer); // RIFF chunk descriptor/identifier \n\n      writeUTFBytes(view, 0, 'RIFF'); // RIFF chunk length\n      // changed \"44\" to \"36\" via #401\n\n      view.setUint32(4, 36 + interleavedLength * 2, true); // RIFF type \n\n      writeUTFBytes(view, 8, 'WAVE'); // format chunk identifier \n      // FMT sub-chunk\n\n      writeUTFBytes(view, 12, 'fmt '); // format chunk length \n\n      view.setUint32(16, 16, true); // sample format (raw)\n\n      view.setUint16(20, 1, true); // stereo (2 channels)\n\n      view.setUint16(22, numberOfAudioChannels, true); // sample rate \n\n      view.setUint32(24, sampleRate, true); // byte rate (sample rate * block align)\n\n      view.setUint32(28, sampleRate * numberOfAudioChannels * 2, true); // block align (channel count * bytes per sample) \n\n      view.setUint16(32, numberOfAudioChannels * 2, true); // bits per sample \n\n      view.setUint16(34, 16, true); // data sub-chunk\n      // data chunk identifier \n\n      writeUTFBytes(view, 36, 'data'); // data chunk length \n\n      view.setUint32(40, interleavedLength * 2, true); // write the PCM samples\n\n      var lng = interleavedLength;\n      var index = 44;\n      var volume = 1;\n\n      for (var i = 0; i < lng; i++) {\n        view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);\n        index += 2;\n      }\n\n      if (cb) {\n        return cb({\n          buffer: buffer,\n          view: view\n        });\n      }\n\n      postMessage({\n        buffer: buffer,\n        view: view\n      });\n    }\n\n    if (config.noWorker) {\n      mergeAudioBuffers(config, function (data) {\n        callback(data.buffer, data.view);\n      });\n      return;\n    }\n\n    var webWorker = processInWebWorker(mergeAudioBuffers);\n\n    webWorker.onmessage = function (event) {\n      callback(event.data.buffer, event.data.view); // release memory\n\n      URL.revokeObjectURL(webWorker.workerURL); // kill webworker (or Chrome will kill your page after ~25 calls)\n\n      webWorker.terminate();\n    };\n\n    webWorker.postMessage(config);\n  }\n\n  function processInWebWorker(_function) {\n    var workerURL = URL.createObjectURL(new Blob([_function.toString(), ';this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'], {\n      type: 'application/javascript'\n    }));\n    var worker = new Worker(workerURL);\n    worker.workerURL = workerURL;\n    return worker;\n  }\n  /**\r\n   * This method stops recording MediaStream.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n\n  this.stop = function (callback) {\n    callback = callback || function () {}; // stop recording\n\n\n    recording = false;\n    mergeLeftRightBuffers({\n      desiredSampRate: desiredSampRate,\n      sampleRate: sampleRate,\n      numberOfAudioChannels: numberOfAudioChannels,\n      internalInterleavedLength: recordingLength,\n      leftBuffers: leftchannel,\n      rightBuffers: numberOfAudioChannels === 1 ? [] : rightchannel,\n      noWorker: config.noWorker\n    }, function (buffer, view) {\n      /**\r\n       * @property {Blob} blob - The recorded blob object.\r\n       * @memberof StereoAudioRecorder\r\n       * @example\r\n       * recorder.stop(function(){\r\n       *     var blob = recorder.blob;\r\n       * });\r\n       */\n      self.blob = new Blob([view], {\n        type: 'audio/wav'\n      });\n      /**\r\n       * @property {ArrayBuffer} buffer - The recorded buffer object.\r\n       * @memberof StereoAudioRecorder\r\n       * @example\r\n       * recorder.stop(function(){\r\n       *     var buffer = recorder.buffer;\r\n       * });\r\n       */\n\n      self.buffer = new ArrayBuffer(view.buffer.byteLength);\n      /**\r\n       * @property {DataView} view - The recorded data-view object.\r\n       * @memberof StereoAudioRecorder\r\n       * @example\r\n       * recorder.stop(function(){\r\n       *     var view = recorder.view;\r\n       * });\r\n       */\n\n      self.view = view;\n      self.sampleRate = desiredSampRate || sampleRate;\n      self.bufferSize = bufferSize; // recorded audio length\n\n      self.length = recordingLength;\n      isAudioProcessStarted = false;\n\n      if (callback) {\n        callback(self.blob);\n      }\n    });\n  };\n\n  if (typeof RecordRTC.Storage === 'undefined') {\n    RecordRTC.Storage = {\n      AudioContextConstructor: null,\n      AudioContext: window.AudioContext || window.webkitAudioContext\n    };\n  }\n\n  if (!RecordRTC.Storage.AudioContextConstructor || RecordRTC.Storage.AudioContextConstructor.state === 'closed') {\n    RecordRTC.Storage.AudioContextConstructor = new RecordRTC.Storage.AudioContext();\n  }\n\n  var context = RecordRTC.Storage.AudioContextConstructor; // creates an audio node from the microphone incoming stream\n\n  var audioInput = context.createMediaStreamSource(mediaStream);\n  var legalBufferValues = [0, 256, 512, 1024, 2048, 4096, 8192, 16384];\n  /**\r\n   * From the spec: This value controls how frequently the audioprocess event is\r\n   * dispatched and how many sample-frames need to be processed each call.\r\n   * Lower values for buffer size will result in a lower (better) latency.\r\n   * Higher values will be necessary to avoid audio breakup and glitches\r\n   * The size of the buffer (in sample-frames) which needs to\r\n   * be processed each time onprocessaudio is called.\r\n   * Legal values are (256, 512, 1024, 2048, 4096, 8192, 16384).\r\n   * @property {number} bufferSize - Buffer-size for how frequently the audioprocess event is dispatched.\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder = new StereoAudioRecorder(mediaStream, {\r\n   *     bufferSize: 4096\r\n   * });\r\n   */\n  // \"0\" means, let chrome decide the most accurate buffer-size for current platform.\n\n  var bufferSize = typeof config.bufferSize === 'undefined' ? 4096 : config.bufferSize;\n\n  if (legalBufferValues.indexOf(bufferSize) === -1) {\n    if (!config.disableLogs) {\n      console.log('Legal values for buffer-size are ' + JSON.stringify(legalBufferValues, null, '\\t'));\n    }\n  }\n\n  if (context.createJavaScriptNode) {\n    jsAudioNode = context.createJavaScriptNode(bufferSize, numberOfAudioChannels, numberOfAudioChannels);\n  } else if (context.createScriptProcessor) {\n    jsAudioNode = context.createScriptProcessor(bufferSize, numberOfAudioChannels, numberOfAudioChannels);\n  } else {\n    throw 'WebAudio API has no support on this browser.';\n  } // connect the stream to the script processor\n\n\n  audioInput.connect(jsAudioNode);\n\n  if (!config.bufferSize) {\n    bufferSize = jsAudioNode.bufferSize; // device buffer-size\n  }\n  /**\r\n   * The sample rate (in sample-frames per second) at which the\r\n   * AudioContext handles audio. It is assumed that all AudioNodes\r\n   * in the context run at this rate. In making this assumption,\r\n   * sample-rate converters or \"varispeed\" processors are not supported\r\n   * in real-time processing.\r\n   * The sampleRate parameter describes the sample-rate of the\r\n   * linear PCM audio data in the buffer in sample-frames per second.\r\n   * An implementation must support sample-rates in at least\r\n   * the range 22050 to 96000.\r\n   * @property {number} sampleRate - Buffer-size for how frequently the audioprocess event is dispatched.\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder = new StereoAudioRecorder(mediaStream, {\r\n   *     sampleRate: 44100\r\n   * });\r\n   */\n\n\n  var sampleRate = typeof config.sampleRate !== 'undefined' ? config.sampleRate : context.sampleRate || 44100;\n\n  if (sampleRate < 22050 || sampleRate > 96000) {\n    // Ref: http://stackoverflow.com/a/26303918/552182\n    if (!config.disableLogs) {\n      console.log('sample-rate must be under range 22050 and 96000.');\n    }\n  }\n\n  if (!config.disableLogs) {\n    if (config.desiredSampRate) {\n      console.log('Desired sample-rate: ' + config.desiredSampRate);\n    }\n  }\n\n  var isPaused = false;\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n  this.pause = function () {\n    isPaused = true;\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    if (isMediaStreamActive() === false) {\n      throw 'Please make sure MediaStream is active.';\n    }\n\n    if (!recording) {\n      if (!config.disableLogs) {\n        console.log('Seems recording has been restarted.');\n      }\n\n      this.record();\n      return;\n    }\n\n    isPaused = false;\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof StereoAudioRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    config.checkForInactiveTracks = false;\n\n    if (recording) {\n      this.stop(clearRecordedDataCB);\n    }\n\n    clearRecordedDataCB();\n  };\n\n  function resetVariables() {\n    leftchannel = [];\n    rightchannel = [];\n    recordingLength = 0;\n    isAudioProcessStarted = false;\n    recording = false;\n    isPaused = false;\n    context = null;\n    self.leftchannel = leftchannel;\n    self.rightchannel = rightchannel;\n    self.numberOfAudioChannels = numberOfAudioChannels;\n    self.desiredSampRate = desiredSampRate;\n    self.sampleRate = sampleRate;\n    self.recordingLength = recordingLength;\n    intervalsBasedBuffers = {\n      left: [],\n      right: [],\n      recordingLength: 0\n    };\n  }\n\n  function clearRecordedDataCB() {\n    if (jsAudioNode) {\n      jsAudioNode.onaudioprocess = null;\n      jsAudioNode.disconnect();\n      jsAudioNode = null;\n    }\n\n    if (audioInput) {\n      audioInput.disconnect();\n      audioInput = null;\n    }\n\n    resetVariables();\n  } // for debugging\n\n\n  this.name = 'StereoAudioRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n\n  var isAudioProcessStarted = false;\n\n  function onAudioProcessDataAvailable(e) {\n    if (isPaused) {\n      return;\n    }\n\n    if (isMediaStreamActive() === false) {\n      if (!config.disableLogs) {\n        console.log('MediaStream seems stopped.');\n      }\n\n      jsAudioNode.disconnect();\n      recording = false;\n    }\n\n    if (!recording) {\n      if (audioInput) {\n        audioInput.disconnect();\n        audioInput = null;\n      }\n\n      return;\n    }\n    /**\r\n     * This method is called on \"onaudioprocess\" event's first invocation.\r\n     * @method {function} onAudioProcessStarted\r\n     * @memberof StereoAudioRecorder\r\n     * @example\r\n     * recorder.onAudioProcessStarted: function() { };\r\n     */\n\n\n    if (!isAudioProcessStarted) {\n      isAudioProcessStarted = true;\n\n      if (config.onAudioProcessStarted) {\n        config.onAudioProcessStarted();\n      }\n\n      if (config.initCallback) {\n        config.initCallback();\n      }\n    }\n\n    var left = e.inputBuffer.getChannelData(0); // we clone the samples\n\n    var chLeft = new Float32Array(left);\n    leftchannel.push(chLeft);\n\n    if (numberOfAudioChannels === 2) {\n      var right = e.inputBuffer.getChannelData(1);\n      var chRight = new Float32Array(right);\n      rightchannel.push(chRight);\n    }\n\n    recordingLength += bufferSize; // export raw PCM\n\n    self.recordingLength = recordingLength;\n\n    if (typeof config.timeSlice !== 'undefined') {\n      intervalsBasedBuffers.recordingLength += bufferSize;\n      intervalsBasedBuffers.left.push(chLeft);\n\n      if (numberOfAudioChannels === 2) {\n        intervalsBasedBuffers.right.push(chRight);\n      }\n    }\n  }\n\n  jsAudioNode.onaudioprocess = onAudioProcessDataAvailable; // to prevent self audio to be connected with speakers\n\n  if (context.createMediaStreamDestination) {\n    jsAudioNode.connect(context.createMediaStreamDestination());\n  } else {\n    jsAudioNode.connect(context.destination);\n  } // export raw PCM\n\n\n  this.leftchannel = leftchannel;\n  this.rightchannel = rightchannel;\n  this.numberOfAudioChannels = numberOfAudioChannels;\n  this.desiredSampRate = desiredSampRate;\n  this.sampleRate = sampleRate;\n  self.recordingLength = recordingLength; // helper for intervals based blobs\n\n  var intervalsBasedBuffers = {\n    left: [],\n    right: [],\n    recordingLength: 0\n  }; // this looper is used to support intervals based blobs (via timeSlice+ondataavailable)\n\n  function looper() {\n    if (!recording || typeof config.ondataavailable !== 'function' || typeof config.timeSlice === 'undefined') {\n      return;\n    }\n\n    if (intervalsBasedBuffers.left.length) {\n      mergeLeftRightBuffers({\n        desiredSampRate: desiredSampRate,\n        sampleRate: sampleRate,\n        numberOfAudioChannels: numberOfAudioChannels,\n        internalInterleavedLength: intervalsBasedBuffers.recordingLength,\n        leftBuffers: intervalsBasedBuffers.left,\n        rightBuffers: numberOfAudioChannels === 1 ? [] : intervalsBasedBuffers.right\n      }, function (buffer, view) {\n        var blob = new Blob([view], {\n          type: 'audio/wav'\n        });\n        config.ondataavailable(blob);\n        setTimeout(looper, config.timeSlice);\n      });\n      intervalsBasedBuffers = {\n        left: [],\n        right: [],\n        recordingLength: 0\n      };\n    } else {\n      setTimeout(looper, config.timeSlice);\n    }\n  }\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.StereoAudioRecorder = StereoAudioRecorder;\n} // _________________\n// CanvasRecorder.js\n\n/**\r\n * CanvasRecorder is a standalone class used by {@link RecordRTC} to bring HTML5-Canvas recording into video WebM. It uses HTML2Canvas library and runs top over {@link Whammy}.\r\n * @summary HTML2Canvas recording into video WebM.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef CanvasRecorder\r\n * @class\r\n * @example\r\n * var recorder = new CanvasRecorder(htmlElement, { disableLogs: true, useWhammyRecorder: true });\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {HTMLElement} htmlElement - querySelector/getElementById/getElementsByTagName[0]/etc.\r\n * @param {object} config - {disableLogs:true, initCallback: function}\r\n */\n\n\nfunction CanvasRecorder(htmlElement, config) {\n  if (typeof html2canvas === 'undefined') {\n    throw 'Please link: https://www.webrtc-experiment.com/screenshot.js';\n  }\n\n  config = config || {};\n\n  if (!config.frameInterval) {\n    config.frameInterval = 10;\n  } // via DetectRTC.js\n\n\n  var isCanvasSupportsStreamCapturing = false;\n  ['captureStream', 'mozCaptureStream', 'webkitCaptureStream'].forEach(function (item) {\n    if (item in document.createElement('canvas')) {\n      isCanvasSupportsStreamCapturing = true;\n    }\n  });\n\n  var _isChrome = (!!window.webkitRTCPeerConnection || !!window.webkitGetUserMedia) && !!window.chrome;\n\n  var chromeVersion = 50;\n  var matchArray = navigator.userAgent.match(/Chrom(e|ium)\\/([0-9]+)\\./);\n\n  if (_isChrome && matchArray && matchArray[2]) {\n    chromeVersion = parseInt(matchArray[2], 10);\n  }\n\n  if (_isChrome && chromeVersion < 52) {\n    isCanvasSupportsStreamCapturing = false;\n  }\n\n  if (config.useWhammyRecorder) {\n    isCanvasSupportsStreamCapturing = false;\n  }\n\n  var globalCanvas, mediaStreamRecorder;\n\n  if (isCanvasSupportsStreamCapturing) {\n    if (!config.disableLogs) {\n      console.log('Your browser supports both MediRecorder API and canvas.captureStream!');\n    }\n\n    if (htmlElement instanceof HTMLCanvasElement) {\n      globalCanvas = htmlElement;\n    } else if (htmlElement instanceof CanvasRenderingContext2D) {\n      globalCanvas = htmlElement.canvas;\n    } else {\n      throw 'Please pass either HTMLCanvasElement or CanvasRenderingContext2D.';\n    }\n  } else if (!!navigator.mozGetUserMedia) {\n    if (!config.disableLogs) {\n      console.error('Canvas recording is NOT supported in Firefox.');\n    }\n  }\n\n  var isRecording;\n  /**\r\n   * This method records Canvas.\r\n   * @method\r\n   * @memberof CanvasRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n  this.record = function () {\n    isRecording = true;\n\n    if (isCanvasSupportsStreamCapturing && !config.useWhammyRecorder) {\n      // CanvasCaptureMediaStream\n      var canvasMediaStream;\n\n      if ('captureStream' in globalCanvas) {\n        canvasMediaStream = globalCanvas.captureStream(25); // 25 FPS\n      } else if ('mozCaptureStream' in globalCanvas) {\n        canvasMediaStream = globalCanvas.mozCaptureStream(25);\n      } else if ('webkitCaptureStream' in globalCanvas) {\n        canvasMediaStream = globalCanvas.webkitCaptureStream(25);\n      }\n\n      try {\n        var mdStream = new MediaStream();\n        mdStream.addTrack(getTracks(canvasMediaStream, 'video')[0]);\n        canvasMediaStream = mdStream;\n      } catch (e) {}\n\n      if (!canvasMediaStream) {\n        throw 'captureStream API are NOT available.';\n      } // Note: Jan 18, 2016 status is that, \n      // Firefox MediaRecorder API can't record CanvasCaptureMediaStream object.\n\n\n      mediaStreamRecorder = new MediaStreamRecorder(canvasMediaStream, {\n        mimeType: config.mimeType || 'video/webm'\n      });\n      mediaStreamRecorder.record();\n    } else {\n      whammy.frames = [];\n      lastTime = new Date().getTime();\n      drawCanvasFrame();\n    }\n\n    if (config.initCallback) {\n      config.initCallback();\n    }\n  };\n\n  this.getWebPImages = function (callback) {\n    if (htmlElement.nodeName.toLowerCase() !== 'canvas') {\n      callback();\n      return;\n    }\n\n    var framesLength = whammy.frames.length;\n    whammy.frames.forEach(function (frame, idx) {\n      var framesRemaining = framesLength - idx;\n\n      if (!config.disableLogs) {\n        console.log(framesRemaining + '/' + framesLength + ' frames remaining');\n      }\n\n      if (config.onEncodingCallback) {\n        config.onEncodingCallback(framesRemaining, framesLength);\n      }\n\n      var webp = frame.image.toDataURL('image/webp', 1);\n      whammy.frames[idx].image = webp;\n    });\n\n    if (!config.disableLogs) {\n      console.log('Generating WebM');\n    }\n\n    callback();\n  };\n  /**\r\n   * This method stops recording Canvas.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof CanvasRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n\n  this.stop = function (callback) {\n    isRecording = false;\n    var that = this;\n\n    if (isCanvasSupportsStreamCapturing && mediaStreamRecorder) {\n      mediaStreamRecorder.stop(callback);\n      return;\n    }\n\n    this.getWebPImages(function () {\n      /**\r\n       * @property {Blob} blob - Recorded frames in video/webm blob.\r\n       * @memberof CanvasRecorder\r\n       * @example\r\n       * recorder.stop(function() {\r\n       *     var blob = recorder.blob;\r\n       * });\r\n       */\n      whammy.compile(function (blob) {\n        if (!config.disableLogs) {\n          console.log('Recording finished!');\n        }\n\n        that.blob = blob;\n\n        if (that.blob.forEach) {\n          that.blob = new Blob([], {\n            type: 'video/webm'\n          });\n        }\n\n        if (callback) {\n          callback(that.blob);\n        }\n\n        whammy.frames = [];\n      });\n    });\n  };\n\n  var isPausedRecording = false;\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof CanvasRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n  this.pause = function () {\n    isPausedRecording = true;\n\n    if (mediaStreamRecorder instanceof MediaStreamRecorder) {\n      mediaStreamRecorder.pause();\n      return;\n    }\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof CanvasRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    isPausedRecording = false;\n\n    if (mediaStreamRecorder instanceof MediaStreamRecorder) {\n      mediaStreamRecorder.resume();\n      return;\n    }\n\n    if (!isRecording) {\n      this.record();\n    }\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof CanvasRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    if (isRecording) {\n      this.stop(clearRecordedDataCB);\n    }\n\n    clearRecordedDataCB();\n  };\n\n  function clearRecordedDataCB() {\n    whammy.frames = [];\n    isRecording = false;\n    isPausedRecording = false;\n  } // for debugging\n\n\n  this.name = 'CanvasRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n\n  function cloneCanvas() {\n    //create a new canvas\n    var newCanvas = document.createElement('canvas');\n    var context = newCanvas.getContext('2d'); //set dimensions\n\n    newCanvas.width = htmlElement.width;\n    newCanvas.height = htmlElement.height; //apply the old canvas to the new one\n\n    context.drawImage(htmlElement, 0, 0); //return the new canvas\n\n    return newCanvas;\n  }\n\n  function drawCanvasFrame() {\n    if (isPausedRecording) {\n      lastTime = new Date().getTime();\n      return setTimeout(drawCanvasFrame, 500);\n    }\n\n    if (htmlElement.nodeName.toLowerCase() === 'canvas') {\n      var duration = new Date().getTime() - lastTime; // via #206, by Jack i.e. @Seymourr\n\n      lastTime = new Date().getTime();\n      whammy.frames.push({\n        image: cloneCanvas(),\n        duration: duration\n      });\n\n      if (isRecording) {\n        setTimeout(drawCanvasFrame, config.frameInterval);\n      }\n\n      return;\n    }\n\n    html2canvas(htmlElement, {\n      grabMouse: typeof config.showMousePointer === 'undefined' || config.showMousePointer,\n      onrendered: function onrendered(canvas) {\n        var duration = new Date().getTime() - lastTime;\n\n        if (!duration) {\n          return setTimeout(drawCanvasFrame, config.frameInterval);\n        } // via #206, by Jack i.e. @Seymourr\n\n\n        lastTime = new Date().getTime();\n        whammy.frames.push({\n          image: canvas.toDataURL('image/webp', 1),\n          duration: duration\n        });\n\n        if (isRecording) {\n          setTimeout(drawCanvasFrame, config.frameInterval);\n        }\n      }\n    });\n  }\n\n  var lastTime = new Date().getTime();\n  var whammy = new Whammy.Video(100);\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.CanvasRecorder = CanvasRecorder;\n} // _________________\n// WhammyRecorder.js\n\n/**\r\n * WhammyRecorder is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It runs top over {@link Whammy}.\r\n * @summary Video recording feature in Chrome.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef WhammyRecorder\r\n * @class\r\n * @example\r\n * var recorder = new WhammyRecorder(mediaStream);\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {disableLogs: true, initCallback: function, video: HTMLVideoElement, etc.}\r\n */\n\n\nfunction WhammyRecorder(mediaStream, config) {\n  config = config || {};\n\n  if (!config.frameInterval) {\n    config.frameInterval = 10;\n  }\n\n  if (!config.disableLogs) {\n    console.log('Using frames-interval:', config.frameInterval);\n  }\n  /**\r\n   * This method records video.\r\n   * @method\r\n   * @memberof WhammyRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n\n  this.record = function () {\n    if (!config.width) {\n      config.width = 320;\n    }\n\n    if (!config.height) {\n      config.height = 240;\n    }\n\n    if (!config.video) {\n      config.video = {\n        width: config.width,\n        height: config.height\n      };\n    }\n\n    if (!config.canvas) {\n      config.canvas = {\n        width: config.width,\n        height: config.height\n      };\n    }\n\n    canvas.width = config.canvas.width || 320;\n    canvas.height = config.canvas.height || 240;\n    context = canvas.getContext('2d'); // setting defaults\n\n    if (config.video && config.video instanceof HTMLVideoElement) {\n      video = config.video.cloneNode();\n\n      if (config.initCallback) {\n        config.initCallback();\n      }\n    } else {\n      video = document.createElement('video');\n      setSrcObject(mediaStream, video);\n\n      video.onloadedmetadata = function () {\n        // \"onloadedmetadata\" may NOT work in FF?\n        if (config.initCallback) {\n          config.initCallback();\n        }\n      };\n\n      video.width = config.video.width;\n      video.height = config.video.height;\n    }\n\n    video.muted = true;\n    video.play();\n    lastTime = new Date().getTime();\n    whammy = new Whammy.Video();\n\n    if (!config.disableLogs) {\n      console.log('canvas resolutions', canvas.width, '*', canvas.height);\n      console.log('video width/height', video.width || canvas.width, '*', video.height || canvas.height);\n    }\n\n    drawFrames(config.frameInterval);\n  };\n  /**\r\n   * Draw and push frames to Whammy\r\n   * @param {integer} frameInterval - set minimum interval (in milliseconds) between each time we push a frame to Whammy\r\n   */\n\n\n  function drawFrames(frameInterval) {\n    frameInterval = typeof frameInterval !== 'undefined' ? frameInterval : 10;\n    var duration = new Date().getTime() - lastTime;\n\n    if (!duration) {\n      return setTimeout(drawFrames, frameInterval, frameInterval);\n    }\n\n    if (isPausedRecording) {\n      lastTime = new Date().getTime();\n      return setTimeout(drawFrames, 100);\n    } // via #206, by Jack i.e. @Seymourr\n\n\n    lastTime = new Date().getTime();\n\n    if (video.paused) {\n      // via: https://github.com/muaz-khan/WebRTC-Experiment/pull/316\n      // Tweak for Android Chrome\n      video.play();\n    }\n\n    context.drawImage(video, 0, 0, canvas.width, canvas.height);\n    whammy.frames.push({\n      duration: duration,\n      image: canvas.toDataURL('image/webp')\n    });\n\n    if (!isStopDrawing) {\n      setTimeout(drawFrames, frameInterval, frameInterval);\n    }\n  }\n\n  function asyncLoop(o) {\n    var i = -1,\n        length = o.length;\n\n    (function loop() {\n      i++;\n\n      if (i === length) {\n        o.callback();\n        return;\n      } // \"setTimeout\" added by Jim McLeod\n\n\n      setTimeout(function () {\n        o.functionToLoop(loop, i);\n      }, 1);\n    })();\n  }\n  /**\r\n   * remove black frames from the beginning to the specified frame\r\n   * @param {Array} _frames - array of frames to be checked\r\n   * @param {number} _framesToCheck - number of frame until check will be executed (-1 - will drop all frames until frame not matched will be found)\r\n   * @param {number} _pixTolerance - 0 - very strict (only black pixel color) ; 1 - all\r\n   * @param {number} _frameTolerance - 0 - very strict (only black frame color) ; 1 - all\r\n   * @returns {Array} - array of frames\r\n   */\n  // pull#293 by @volodalexey\n\n\n  function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance, _callback2) {\n    var localCanvas = document.createElement('canvas');\n    localCanvas.width = canvas.width;\n    localCanvas.height = canvas.height;\n    var context2d = localCanvas.getContext('2d');\n    var resultFrames = [];\n    var checkUntilNotBlack = _framesToCheck === -1;\n    var endCheckFrame = _framesToCheck && _framesToCheck > 0 && _framesToCheck <= _frames.length ? _framesToCheck : _frames.length;\n    var sampleColor = {\n      r: 0,\n      g: 0,\n      b: 0\n    };\n    var maxColorDifference = Math.sqrt(Math.pow(255, 2) + Math.pow(255, 2) + Math.pow(255, 2));\n    var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;\n    var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;\n    var doNotCheckNext = false;\n    asyncLoop({\n      length: endCheckFrame,\n      functionToLoop: function functionToLoop(loop, f) {\n        var matchPixCount, endPixCheck, maxPixCount;\n\n        var finishImage = function finishImage() {\n          if (!doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {// console.log('removed black frame : ' + f + ' ; frame duration ' + _frames[f].duration);\n          } else {\n            // console.log('frame is passed : ' + f);\n            if (checkUntilNotBlack) {\n              doNotCheckNext = true;\n            }\n\n            resultFrames.push(_frames[f]);\n          }\n\n          loop();\n        };\n\n        if (!doNotCheckNext) {\n          var image = new Image();\n\n          image.onload = function () {\n            context2d.drawImage(image, 0, 0, canvas.width, canvas.height);\n            var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);\n            matchPixCount = 0;\n            endPixCheck = imageData.data.length;\n            maxPixCount = imageData.data.length / 4;\n\n            for (var pix = 0; pix < endPixCheck; pix += 4) {\n              var currentColor = {\n                r: imageData.data[pix],\n                g: imageData.data[pix + 1],\n                b: imageData.data[pix + 2]\n              };\n              var colorDifference = Math.sqrt(Math.pow(currentColor.r - sampleColor.r, 2) + Math.pow(currentColor.g - sampleColor.g, 2) + Math.pow(currentColor.b - sampleColor.b, 2)); // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)\n\n              if (colorDifference <= maxColorDifference * pixTolerance) {\n                matchPixCount++;\n              }\n            }\n\n            finishImage();\n          };\n\n          image.src = _frames[f].image;\n        } else {\n          finishImage();\n        }\n      },\n      callback: function callback() {\n        resultFrames = resultFrames.concat(_frames.slice(endCheckFrame));\n\n        if (resultFrames.length <= 0) {\n          // at least one last frame should be available for next manipulation\n          // if total duration of all frames will be < 1000 than ffmpeg doesn't work well...\n          resultFrames.push(_frames[_frames.length - 1]);\n        }\n\n        _callback2(resultFrames);\n      }\n    });\n  }\n\n  var isStopDrawing = false;\n  /**\r\n   * This method stops recording video.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof WhammyRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n  this.stop = function (callback) {\n    callback = callback || function () {};\n\n    isStopDrawing = true;\n\n    var _this = this; // analyse of all frames takes some time!\n\n\n    setTimeout(function () {\n      // e.g. dropBlackFrames(frames, 10, 1, 1) - will cut all 10 frames\n      // e.g. dropBlackFrames(frames, 10, 0.5, 0.5) - will analyse 10 frames\n      // e.g. dropBlackFrames(frames, 10) === dropBlackFrames(frames, 10, 0, 0) - will analyse 10 frames with strict black color\n      dropBlackFrames(whammy.frames, -1, null, null, function (frames) {\n        whammy.frames = frames; // to display advertisement images!\n\n        if (config.advertisement && config.advertisement.length) {\n          whammy.frames = config.advertisement.concat(whammy.frames);\n        }\n        /**\r\n         * @property {Blob} blob - Recorded frames in video/webm blob.\r\n         * @memberof WhammyRecorder\r\n         * @example\r\n         * recorder.stop(function() {\r\n         *     var blob = recorder.blob;\r\n         * });\r\n         */\n\n\n        whammy.compile(function (blob) {\n          _this.blob = blob;\n\n          if (_this.blob.forEach) {\n            _this.blob = new Blob([], {\n              type: 'video/webm'\n            });\n          }\n\n          if (callback) {\n            callback(_this.blob);\n          }\n        });\n      });\n    }, 10);\n  };\n\n  var isPausedRecording = false;\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof WhammyRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n  this.pause = function () {\n    isPausedRecording = true;\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof WhammyRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    isPausedRecording = false;\n\n    if (isStopDrawing) {\n      this.record();\n    }\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof WhammyRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    if (!isStopDrawing) {\n      this.stop(clearRecordedDataCB);\n    }\n\n    clearRecordedDataCB();\n  };\n\n  function clearRecordedDataCB() {\n    whammy.frames = [];\n    isStopDrawing = true;\n    isPausedRecording = false;\n  } // for debugging\n\n\n  this.name = 'WhammyRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n\n  var canvas = document.createElement('canvas');\n  var context = canvas.getContext('2d');\n  var video;\n  var lastTime;\n  var whammy;\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.WhammyRecorder = WhammyRecorder;\n} // https://github.com/antimatter15/whammy/blob/master/LICENSE\n// _________\n// Whammy.js\n// todo: Firefox now supports webp for webm containers!\n// their MediaRecorder implementation works well!\n// should we provide an option to record via Whammy.js or MediaRecorder API is a better solution?\n\n/**\r\n * Whammy is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It is written by {@link https://github.com/antimatter15|antimatter15}\r\n * @summary A real time javascript webm encoder based on a canvas hack.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef Whammy\r\n * @class\r\n * @example\r\n * var recorder = new Whammy().Video(15);\r\n * recorder.add(context || canvas || dataURL);\r\n * var output = recorder.compile();\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nvar Whammy = function () {\n  // a more abstract-ish API\n  function WhammyVideo(duration) {\n    this.frames = [];\n    this.duration = duration || 1;\n    this.quality = 0.8;\n  }\n  /**\r\n   * Pass Canvas or Context or image/webp(string) to {@link Whammy} encoder.\r\n   * @method\r\n   * @memberof Whammy\r\n   * @example\r\n   * recorder = new Whammy().Video(0.8, 100);\r\n   * recorder.add(canvas || context || 'image/webp');\r\n   * @param {string} frame - Canvas || Context || image/webp\r\n   * @param {number} duration - Stick a duration (in milliseconds)\r\n   */\n\n\n  WhammyVideo.prototype.add = function (frame, duration) {\n    if ('canvas' in frame) {\n      //CanvasRenderingContext2D\n      frame = frame.canvas;\n    }\n\n    if ('toDataURL' in frame) {\n      frame = frame.toDataURL('image/webp', this.quality);\n    }\n\n    if (!/^data:image\\/webp;base64,/ig.test(frame)) {\n      throw 'Input must be formatted properly as a base64 encoded DataURI of type image/webp';\n    }\n\n    this.frames.push({\n      image: frame,\n      duration: duration || this.duration\n    });\n  };\n\n  function processInWebWorker(_function) {\n    var blob = URL.createObjectURL(new Blob([_function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}'], {\n      type: 'application/javascript'\n    }));\n    var worker = new Worker(blob);\n    URL.revokeObjectURL(blob);\n    return worker;\n  }\n\n  function whammyInWebWorker(frames) {\n    function ArrayToWebM(frames) {\n      var info = checkFrames(frames);\n\n      if (!info) {\n        return [];\n      }\n\n      var clusterMaxDuration = 30000;\n      var EBML = [{\n        'id': 0x1a45dfa3,\n        // EBML\n        'data': [{\n          'data': 1,\n          'id': 0x4286 // EBMLVersion\n\n        }, {\n          'data': 1,\n          'id': 0x42f7 // EBMLReadVersion\n\n        }, {\n          'data': 4,\n          'id': 0x42f2 // EBMLMaxIDLength\n\n        }, {\n          'data': 8,\n          'id': 0x42f3 // EBMLMaxSizeLength\n\n        }, {\n          'data': 'webm',\n          'id': 0x4282 // DocType\n\n        }, {\n          'data': 2,\n          'id': 0x4287 // DocTypeVersion\n\n        }, {\n          'data': 2,\n          'id': 0x4285 // DocTypeReadVersion\n\n        }]\n      }, {\n        'id': 0x18538067,\n        // Segment\n        'data': [{\n          'id': 0x1549a966,\n          // Info\n          'data': [{\n            'data': 1e6,\n            //do things in millisecs (num of nanosecs for duration scale)\n            'id': 0x2ad7b1 // TimecodeScale\n\n          }, {\n            'data': 'whammy',\n            'id': 0x4d80 // MuxingApp\n\n          }, {\n            'data': 'whammy',\n            'id': 0x5741 // WritingApp\n\n          }, {\n            'data': doubleToString(info.duration),\n            'id': 0x4489 // Duration\n\n          }]\n        }, {\n          'id': 0x1654ae6b,\n          // Tracks\n          'data': [{\n            'id': 0xae,\n            // TrackEntry\n            'data': [{\n              'data': 1,\n              'id': 0xd7 // TrackNumber\n\n            }, {\n              'data': 1,\n              'id': 0x73c5 // TrackUID\n\n            }, {\n              'data': 0,\n              'id': 0x9c // FlagLacing\n\n            }, {\n              'data': 'und',\n              'id': 0x22b59c // Language\n\n            }, {\n              'data': 'V_VP8',\n              'id': 0x86 // CodecID\n\n            }, {\n              'data': 'VP8',\n              'id': 0x258688 // CodecName\n\n            }, {\n              'data': 1,\n              'id': 0x83 // TrackType\n\n            }, {\n              'id': 0xe0,\n              // Video\n              'data': [{\n                'data': info.width,\n                'id': 0xb0 // PixelWidth\n\n              }, {\n                'data': info.height,\n                'id': 0xba // PixelHeight\n\n              }]\n            }]\n          }]\n        }]\n      }]; //Generate clusters (max duration)\n\n      var frameNumber = 0;\n      var clusterTimecode = 0;\n\n      while (frameNumber < frames.length) {\n        var clusterFrames = [];\n        var clusterDuration = 0;\n\n        do {\n          clusterFrames.push(frames[frameNumber]);\n          clusterDuration += frames[frameNumber].duration;\n          frameNumber++;\n        } while (frameNumber < frames.length && clusterDuration < clusterMaxDuration);\n\n        var clusterCounter = 0;\n        var cluster = {\n          'id': 0x1f43b675,\n          // Cluster\n          'data': getClusterData(clusterTimecode, clusterCounter, clusterFrames)\n        }; //Add cluster to segment\n\n        EBML[1].data.push(cluster);\n        clusterTimecode += clusterDuration;\n      }\n\n      return generateEBML(EBML);\n    }\n\n    function getClusterData(clusterTimecode, clusterCounter, clusterFrames) {\n      return [{\n        'data': clusterTimecode,\n        'id': 0xe7 // Timecode\n\n      }].concat(clusterFrames.map(function (webp) {\n        var block = makeSimpleBlock({\n          discardable: 0,\n          frame: webp.data.slice(4),\n          invisible: 0,\n          keyframe: 1,\n          lacing: 0,\n          trackNum: 1,\n          timecode: Math.round(clusterCounter)\n        });\n        clusterCounter += webp.duration;\n        return {\n          data: block,\n          id: 0xa3\n        };\n      }));\n    } // sums the lengths of all the frames and gets the duration\n\n\n    function checkFrames(frames) {\n      if (!frames[0]) {\n        postMessage({\n          error: 'Something went wrong. Maybe WebP format is not supported in the current browser.'\n        });\n        return;\n      }\n\n      var width = frames[0].width,\n          height = frames[0].height,\n          duration = frames[0].duration;\n\n      for (var i = 1; i < frames.length; i++) {\n        duration += frames[i].duration;\n      }\n\n      return {\n        duration: duration,\n        width: width,\n        height: height\n      };\n    }\n\n    function numToBuffer(num) {\n      var parts = [];\n\n      while (num > 0) {\n        parts.push(num & 0xff);\n        num = num >> 8;\n      }\n\n      return new Uint8Array(parts.reverse());\n    }\n\n    function strToBuffer(str) {\n      return new Uint8Array(str.split('').map(function (e) {\n        return e.charCodeAt(0);\n      }));\n    }\n\n    function bitsToBuffer(bits) {\n      var data = [];\n      var pad = bits.length % 8 ? new Array(1 + 8 - bits.length % 8).join('0') : '';\n      bits = pad + bits;\n\n      for (var i = 0; i < bits.length; i += 8) {\n        data.push(parseInt(bits.substr(i, 8), 2));\n      }\n\n      return new Uint8Array(data);\n    }\n\n    function generateEBML(json) {\n      var ebml = [];\n\n      for (var i = 0; i < json.length; i++) {\n        var data = json[i].data;\n\n        if (_typeof(data) === 'object') {\n          data = generateEBML(data);\n        }\n\n        if (typeof data === 'number') {\n          data = bitsToBuffer(data.toString(2));\n        }\n\n        if (typeof data === 'string') {\n          data = strToBuffer(data);\n        }\n\n        var len = data.size || data.byteLength || data.length;\n        var zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8);\n        var sizeToString = len.toString(2);\n        var padded = new Array(zeroes * 7 + 7 + 1 - sizeToString.length).join('0') + sizeToString;\n        var size = new Array(zeroes).join('0') + '1' + padded;\n        ebml.push(numToBuffer(json[i].id));\n        ebml.push(bitsToBuffer(size));\n        ebml.push(data);\n      }\n\n      return new Blob(ebml, {\n        type: 'video/webm'\n      });\n    }\n\n    function toBinStrOld(bits) {\n      var data = '';\n      var pad = bits.length % 8 ? new Array(1 + 8 - bits.length % 8).join('0') : '';\n      bits = pad + bits;\n\n      for (var i = 0; i < bits.length; i += 8) {\n        data += String.fromCharCode(parseInt(bits.substr(i, 8), 2));\n      }\n\n      return data;\n    }\n\n    function makeSimpleBlock(data) {\n      var flags = 0;\n\n      if (data.keyframe) {\n        flags |= 128;\n      }\n\n      if (data.invisible) {\n        flags |= 8;\n      }\n\n      if (data.lacing) {\n        flags |= data.lacing << 1;\n      }\n\n      if (data.discardable) {\n        flags |= 1;\n      }\n\n      if (data.trackNum > 127) {\n        throw 'TrackNumber > 127 not supported';\n      }\n\n      var out = [data.trackNum | 0x80, data.timecode >> 8, data.timecode & 0xff, flags].map(function (e) {\n        return String.fromCharCode(e);\n      }).join('') + data.frame;\n      return out;\n    }\n\n    function parseWebP(riff) {\n      var VP8 = riff.RIFF[0].WEBP[0];\n      var frameStart = VP8.indexOf('\\x9d\\x01\\x2a'); // A VP8 keyframe starts with the 0x9d012a header\n\n      for (var i = 0, c = []; i < 4; i++) {\n        c[i] = VP8.charCodeAt(frameStart + 3 + i);\n      }\n\n      var width, height, tmp; //the code below is literally copied verbatim from the bitstream spec\n\n      tmp = c[1] << 8 | c[0];\n      width = tmp & 0x3FFF;\n      tmp = c[3] << 8 | c[2];\n      height = tmp & 0x3FFF;\n      return {\n        width: width,\n        height: height,\n        data: VP8,\n        riff: riff\n      };\n    }\n\n    function getStrLength(string, offset) {\n      return parseInt(string.substr(offset + 4, 4).split('').map(function (i) {\n        var unpadded = i.charCodeAt(0).toString(2);\n        return new Array(8 - unpadded.length + 1).join('0') + unpadded;\n      }).join(''), 2);\n    }\n\n    function parseRIFF(string) {\n      var offset = 0;\n      var chunks = {};\n\n      while (offset < string.length) {\n        var id = string.substr(offset, 4);\n        var len = getStrLength(string, offset);\n        var data = string.substr(offset + 4 + 4, len);\n        offset += 4 + 4 + len;\n        chunks[id] = chunks[id] || [];\n\n        if (id === 'RIFF' || id === 'LIST') {\n          chunks[id].push(parseRIFF(data));\n        } else {\n          chunks[id].push(data);\n        }\n      }\n\n      return chunks;\n    }\n\n    function doubleToString(num) {\n      return [].slice.call(new Uint8Array(new Float64Array([num]).buffer), 0).map(function (e) {\n        return String.fromCharCode(e);\n      }).reverse().join('');\n    }\n\n    var webm = new ArrayToWebM(frames.map(function (frame) {\n      var webp = parseWebP(parseRIFF(atob(frame.image.slice(23))));\n      webp.duration = frame.duration;\n      return webp;\n    }));\n    postMessage(webm);\n  }\n  /**\r\n   * Encodes frames in WebM container. It uses WebWorkinvoke to invoke 'ArrayToWebM' method.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof Whammy\r\n   * @example\r\n   * recorder = new Whammy().Video(0.8, 100);\r\n   * recorder.compile(function(blob) {\r\n   *    // blob.size - blob.type\r\n   * });\r\n   */\n\n\n  WhammyVideo.prototype.compile = function (callback) {\n    var webWorker = processInWebWorker(whammyInWebWorker);\n\n    webWorker.onmessage = function (event) {\n      if (event.data.error) {\n        console.error(event.data.error);\n        return;\n      }\n\n      callback(event.data);\n    };\n\n    webWorker.postMessage(this.frames);\n  };\n\n  return {\n    /**\r\n     * A more abstract-ish API.\r\n     * @method\r\n     * @memberof Whammy\r\n     * @example\r\n     * recorder = new Whammy().Video(0.8, 100);\r\n     * @param {?number} speed - 0.8\r\n     * @param {?number} quality - 100\r\n     */\n    Video: WhammyVideo\n  };\n}();\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.Whammy = Whammy;\n} // ______________ (indexed-db)\n// DiskStorage.js\n\n/**\r\n * DiskStorage is a standalone object used by {@link RecordRTC} to store recorded blobs in IndexedDB storage.\r\n * @summary Writing blobs into IndexedDB.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @example\r\n * DiskStorage.Store({\r\n *     audioBlob: yourAudioBlob,\r\n *     videoBlob: yourVideoBlob,\r\n *     gifBlob  : yourGifBlob\r\n * });\r\n * DiskStorage.Fetch(function(dataURL, type) {\r\n *     if(type === 'audioBlob') { }\r\n *     if(type === 'videoBlob') { }\r\n *     if(type === 'gifBlob')   { }\r\n * });\r\n * // DiskStorage.dataStoreName = 'recordRTC';\r\n * // DiskStorage.onError = function(error) { };\r\n * @property {function} init - This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.\r\n * @property {function} Fetch - This method fetches stored blobs from IndexedDB.\r\n * @property {function} Store - This method stores blobs in IndexedDB.\r\n * @property {function} onError - This function is invoked for any known/unknown error.\r\n * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n */\n\n\nvar DiskStorage = {\n  /**\r\n   * This method must be called once to initialize IndexedDB ObjectStore. Though, it is auto-used internally.\r\n   * @method\r\n   * @memberof DiskStorage\r\n   * @internal\r\n   * @example\r\n   * DiskStorage.init();\r\n   */\n  init: function init() {\n    var self = this;\n\n    if (typeof indexedDB === 'undefined' || typeof indexedDB.open === 'undefined') {\n      console.error('IndexedDB API are not available in this browser.');\n      return;\n    }\n\n    var dbVersion = 1;\n    var dbName = this.dbName || location.href.replace(/\\/|:|#|%|\\.|\\[|\\]/g, ''),\n        db;\n    var request = indexedDB.open(dbName, dbVersion);\n\n    function createObjectStore(dataBase) {\n      dataBase.createObjectStore(self.dataStoreName);\n    }\n\n    function putInDB() {\n      var transaction = db.transaction([self.dataStoreName], 'readwrite');\n\n      if (self.videoBlob) {\n        transaction.objectStore(self.dataStoreName).put(self.videoBlob, 'videoBlob');\n      }\n\n      if (self.gifBlob) {\n        transaction.objectStore(self.dataStoreName).put(self.gifBlob, 'gifBlob');\n      }\n\n      if (self.audioBlob) {\n        transaction.objectStore(self.dataStoreName).put(self.audioBlob, 'audioBlob');\n      }\n\n      function getFromStore(portionName) {\n        transaction.objectStore(self.dataStoreName).get(portionName).onsuccess = function (event) {\n          if (self.callback) {\n            self.callback(event.target.result, portionName);\n          }\n        };\n      }\n\n      getFromStore('audioBlob');\n      getFromStore('videoBlob');\n      getFromStore('gifBlob');\n    }\n\n    request.onerror = self.onError;\n\n    request.onsuccess = function () {\n      db = request.result;\n      db.onerror = self.onError;\n\n      if (db.setVersion) {\n        if (db.version !== dbVersion) {\n          var setVersion = db.setVersion(dbVersion);\n\n          setVersion.onsuccess = function () {\n            createObjectStore(db);\n            putInDB();\n          };\n        } else {\n          putInDB();\n        }\n      } else {\n        putInDB();\n      }\n    };\n\n    request.onupgradeneeded = function (event) {\n      createObjectStore(event.target.result);\n    };\n  },\n\n  /**\r\n   * This method fetches stored blobs from IndexedDB.\r\n   * @method\r\n   * @memberof DiskStorage\r\n   * @internal\r\n   * @example\r\n   * DiskStorage.Fetch(function(dataURL, type) {\r\n   *     if(type === 'audioBlob') { }\r\n   *     if(type === 'videoBlob') { }\r\n   *     if(type === 'gifBlob')   { }\r\n   * });\r\n   */\n  Fetch: function Fetch(callback) {\n    this.callback = callback;\n    this.init();\n    return this;\n  },\n\n  /**\r\n   * This method stores blobs in IndexedDB.\r\n   * @method\r\n   * @memberof DiskStorage\r\n   * @internal\r\n   * @example\r\n   * DiskStorage.Store({\r\n   *     audioBlob: yourAudioBlob,\r\n   *     videoBlob: yourVideoBlob,\r\n   *     gifBlob  : yourGifBlob\r\n   * });\r\n   */\n  Store: function Store(config) {\n    this.audioBlob = config.audioBlob;\n    this.videoBlob = config.videoBlob;\n    this.gifBlob = config.gifBlob;\n    this.init();\n    return this;\n  },\n\n  /**\r\n   * This function is invoked for any known/unknown error.\r\n   * @method\r\n   * @memberof DiskStorage\r\n   * @internal\r\n   * @example\r\n   * DiskStorage.onError = function(error){\r\n   *     alerot( JSON.stringify(error) );\r\n   * };\r\n   */\n  onError: function onError(error) {\n    console.error(JSON.stringify(error, null, '\\t'));\n  },\n\n  /**\r\n   * @property {string} dataStoreName - Name of the ObjectStore created in IndexedDB storage.\r\n   * @memberof DiskStorage\r\n   * @internal\r\n   * @example\r\n   * DiskStorage.dataStoreName = 'recordRTC';\r\n   */\n  dataStoreName: 'recordRTC',\n  dbName: null\n};\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.DiskStorage = DiskStorage;\n} // ______________\n// GifRecorder.js\n\n/**\r\n * GifRecorder is standalone calss used by {@link RecordRTC} to record video or canvas into animated gif.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef GifRecorder\r\n * @class\r\n * @example\r\n * var recorder = new GifRecorder(mediaStream || canvas || context, { onGifPreview: function, onGifRecordingStarted: function, width: 1280, height: 720, frameRate: 200, quality: 10 });\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     img.src = URL.createObjectURL(blob);\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object or HTMLCanvasElement or CanvasRenderingContext2D.\r\n * @param {object} config - {disableLogs:true, initCallback: function, width: 320, height: 240, frameRate: 200, quality: 10}\r\n */\n\n\nfunction GifRecorder(mediaStream, config) {\n  if (typeof GIFEncoder === 'undefined') {\n    var script = document.createElement('script');\n    script.src = 'https://www.webrtc-experiment.com/gif-recorder.js';\n    (document.body || document.documentElement).appendChild(script);\n  }\n\n  config = config || {};\n  var isHTMLObject = mediaStream instanceof CanvasRenderingContext2D || mediaStream instanceof HTMLCanvasElement;\n  /**\r\n   * This method records MediaStream.\r\n   * @method\r\n   * @memberof GifRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n  this.record = function () {\n    if (typeof GIFEncoder === 'undefined') {\n      setTimeout(self.record, 1000);\n      return;\n    }\n\n    if (!isLoadedMetaData) {\n      setTimeout(self.record, 1000);\n      return;\n    }\n\n    if (!isHTMLObject) {\n      if (!config.width) {\n        config.width = video.offsetWidth || 320;\n      }\n\n      if (!config.height) {\n        config.height = video.offsetHeight || 240;\n      }\n\n      if (!config.video) {\n        config.video = {\n          width: config.width,\n          height: config.height\n        };\n      }\n\n      if (!config.canvas) {\n        config.canvas = {\n          width: config.width,\n          height: config.height\n        };\n      }\n\n      canvas.width = config.canvas.width || 320;\n      canvas.height = config.canvas.height || 240;\n      video.width = config.video.width || 320;\n      video.height = config.video.height || 240;\n    } // external library to record as GIF images\n\n\n    gifEncoder = new GIFEncoder(); // void setRepeat(int iter) \n    // Sets the number of times the set of GIF frames should be played. \n    // Default is 1; 0 means play indefinitely.\n\n    gifEncoder.setRepeat(0); // void setFrameRate(Number fps) \n    // Sets frame rate in frames per second. \n    // Equivalent to setDelay(1000/fps).\n    // Using \"setDelay\" instead of \"setFrameRate\"\n\n    gifEncoder.setDelay(config.frameRate || 200); // void setQuality(int quality) \n    // Sets quality of color quantization (conversion of images to the \n    // maximum 256 colors allowed by the GIF specification). \n    // Lower values (minimum = 1) produce better colors, \n    // but slow processing significantly. 10 is the default, \n    // and produces good color mapping at reasonable speeds. \n    // Values greater than 20 do not yield significant improvements in speed.\n\n    gifEncoder.setQuality(config.quality || 10); // Boolean start() \n    // This writes the GIF Header and returns false if it fails.\n\n    gifEncoder.start();\n\n    if (typeof config.onGifRecordingStarted === 'function') {\n      config.onGifRecordingStarted();\n    }\n\n    startTime = Date.now();\n\n    function drawVideoFrame(time) {\n      if (self.clearedRecordedData === true) {\n        return;\n      }\n\n      if (isPausedRecording) {\n        return setTimeout(function () {\n          drawVideoFrame(time);\n        }, 100);\n      }\n\n      lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n      if (_typeof(lastFrameTime) === undefined) {\n        lastFrameTime = time;\n      } // ~10 fps\n\n\n      if (time - lastFrameTime < 90) {\n        return;\n      }\n\n      if (!isHTMLObject && video.paused) {\n        // via: https://github.com/muaz-khan/WebRTC-Experiment/pull/316\n        // Tweak for Android Chrome\n        video.play();\n      }\n\n      if (!isHTMLObject) {\n        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n      }\n\n      if (config.onGifPreview) {\n        config.onGifPreview(canvas.toDataURL('image/png'));\n      }\n\n      gifEncoder.addFrame(context);\n      lastFrameTime = time;\n    }\n\n    lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n    if (config.initCallback) {\n      config.initCallback();\n    }\n  };\n  /**\r\n   * This method stops recording MediaStream.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof GifRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     img.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n\n  this.stop = function (callback) {\n    callback = callback || function () {};\n\n    if (lastAnimationFrame) {\n      cancelAnimationFrame(lastAnimationFrame);\n    }\n\n    endTime = Date.now();\n    /**\r\n     * @property {Blob} blob - The recorded blob object.\r\n     * @memberof GifRecorder\r\n     * @example\r\n     * recorder.stop(function(){\r\n     *     var blob = recorder.blob;\r\n     * });\r\n     */\n\n    this.blob = new Blob([new Uint8Array(gifEncoder.stream().bin)], {\n      type: 'image/gif'\n    });\n    callback(this.blob); // bug: find a way to clear old recorded blobs\n\n    gifEncoder.stream().bin = [];\n  };\n\n  var isPausedRecording = false;\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof GifRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n  this.pause = function () {\n    isPausedRecording = true;\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof GifRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    isPausedRecording = false;\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof GifRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    self.clearedRecordedData = true;\n    clearRecordedDataCB();\n  };\n\n  function clearRecordedDataCB() {\n    if (gifEncoder) {\n      gifEncoder.stream().bin = [];\n    }\n  } // for debugging\n\n\n  this.name = 'GifRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n\n  var canvas = document.createElement('canvas');\n  var context = canvas.getContext('2d');\n\n  if (isHTMLObject) {\n    if (mediaStream instanceof CanvasRenderingContext2D) {\n      context = mediaStream;\n      canvas = context.canvas;\n    } else if (mediaStream instanceof HTMLCanvasElement) {\n      context = mediaStream.getContext('2d');\n      canvas = mediaStream;\n    }\n  }\n\n  var isLoadedMetaData = true;\n\n  if (!isHTMLObject) {\n    var video = document.createElement('video');\n    video.muted = true;\n    video.autoplay = true;\n    video.playsInline = true;\n    isLoadedMetaData = false;\n\n    video.onloadedmetadata = function () {\n      isLoadedMetaData = true;\n    };\n\n    setSrcObject(mediaStream, video);\n    video.play();\n  }\n\n  var lastAnimationFrame = null;\n  var startTime, endTime, lastFrameTime;\n  var gifEncoder;\n  var self = this;\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.GifRecorder = GifRecorder;\n} // Last time updated: 2019-06-21 4:09:42 AM UTC\n// ________________________\n// MultiStreamsMixer v1.2.2\n// Open-Sourced: https://github.com/muaz-khan/MultiStreamsMixer\n// --------------------------------------------------\n// Muaz Khan     - www.MuazKhan.com\n// MIT License   - www.WebRTC-Experiment.com/licence\n// --------------------------------------------------\n\n\nfunction MultiStreamsMixer(arrayOfMediaStreams, elementClass) {\n  var browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';\n\n  (function (that) {\n    if (typeof RecordRTC !== 'undefined') {\n      return;\n    }\n\n    if (!that) {\n      return;\n    }\n\n    if (typeof window !== 'undefined') {\n      return;\n    }\n\n    if (typeof global === 'undefined') {\n      return;\n    }\n\n    global.navigator = {\n      userAgent: browserFakeUserAgent,\n      getUserMedia: function getUserMedia() {}\n    };\n\n    if (!global.console) {\n      global.console = {};\n    }\n\n    if (typeof global.console.log === 'undefined' || typeof global.console.error === 'undefined') {\n      global.console.error = global.console.log = global.console.log || function () {\n        console.log(arguments);\n      };\n    }\n\n    if (typeof document === 'undefined') {\n      /*global document:true */\n      that.document = {\n        documentElement: {\n          appendChild: function appendChild() {\n            return '';\n          }\n        }\n      };\n\n      document.createElement = document.captureStream = document.mozCaptureStream = function () {\n        var obj = {\n          getContext: function getContext() {\n            return obj;\n          },\n          play: function play() {},\n          pause: function pause() {},\n          drawImage: function drawImage() {},\n          toDataURL: function toDataURL() {\n            return '';\n          },\n          style: {}\n        };\n        return obj;\n      };\n\n      that.HTMLVideoElement = function () {};\n    }\n\n    if (typeof location === 'undefined') {\n      /*global location:true */\n      that.location = {\n        protocol: 'file:',\n        href: '',\n        hash: ''\n      };\n    }\n\n    if (typeof screen === 'undefined') {\n      /*global screen:true */\n      that.screen = {\n        width: 0,\n        height: 0\n      };\n    }\n\n    if (typeof URL === 'undefined') {\n      /*global screen:true */\n      that.URL = {\n        createObjectURL: function createObjectURL() {\n          return '';\n        },\n        revokeObjectURL: function revokeObjectURL() {\n          return '';\n        }\n      };\n    }\n    /*global window:true */\n\n\n    that.window = global;\n  })(typeof global !== 'undefined' ? global : null); // requires: chrome://flags/#enable-experimental-web-platform-features\n\n\n  elementClass = elementClass || 'multi-streams-mixer';\n  var videos = [];\n  var isStopDrawingFrames = false;\n  var canvas = document.createElement('canvas');\n  var context = canvas.getContext('2d');\n  canvas.style.opacity = 0;\n  canvas.style.position = 'absolute';\n  canvas.style.zIndex = -1;\n  canvas.style.top = '-1000em';\n  canvas.style.left = '-1000em';\n  canvas.className = elementClass;\n  (document.body || document.documentElement).appendChild(canvas);\n  this.disableLogs = false;\n  this.frameInterval = 10;\n  this.width = 360;\n  this.height = 240; // use gain node to prevent echo\n\n  this.useGainNode = true;\n  var self = this; // _____________________________\n  // Cross-Browser-Declarations.js\n  // WebAudio API representer\n\n  var AudioContext = window.AudioContext;\n\n  if (typeof AudioContext === 'undefined') {\n    if (typeof webkitAudioContext !== 'undefined') {\n      /*global AudioContext:true */\n      AudioContext = webkitAudioContext;\n    }\n\n    if (typeof mozAudioContext !== 'undefined') {\n      /*global AudioContext:true */\n      AudioContext = mozAudioContext;\n    }\n  }\n  /*jshint -W079 */\n\n\n  var URL = window.URL;\n\n  if (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {\n    /*global URL:true */\n    URL = webkitURL;\n  }\n\n  if (typeof navigator !== 'undefined' && typeof navigator.getUserMedia === 'undefined') {\n    // maybe window.navigator?\n    if (typeof navigator.webkitGetUserMedia !== 'undefined') {\n      navigator.getUserMedia = navigator.webkitGetUserMedia;\n    }\n\n    if (typeof navigator.mozGetUserMedia !== 'undefined') {\n      navigator.getUserMedia = navigator.mozGetUserMedia;\n    }\n  }\n\n  var MediaStream = window.MediaStream;\n\n  if (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {\n    MediaStream = webkitMediaStream;\n  }\n  /*global MediaStream:true */\n\n\n  if (typeof MediaStream !== 'undefined') {\n    // override \"stop\" method for all browsers\n    if (typeof MediaStream.prototype.stop === 'undefined') {\n      MediaStream.prototype.stop = function () {\n        this.getTracks().forEach(function (track) {\n          track.stop();\n        });\n      };\n    }\n  }\n\n  var Storage = {};\n\n  if (typeof AudioContext !== 'undefined') {\n    Storage.AudioContext = AudioContext;\n  } else if (typeof webkitAudioContext !== 'undefined') {\n    Storage.AudioContext = webkitAudioContext;\n  }\n\n  function setSrcObject(stream, element) {\n    if ('srcObject' in element) {\n      element.srcObject = stream;\n    } else if ('mozSrcObject' in element) {\n      element.mozSrcObject = stream;\n    } else {\n      element.srcObject = stream;\n    }\n  }\n\n  this.startDrawingFrames = function () {\n    drawVideosToCanvas();\n  };\n\n  function drawVideosToCanvas() {\n    if (isStopDrawingFrames) {\n      return;\n    }\n\n    var videosLength = videos.length;\n    var fullcanvas = false;\n    var remaining = [];\n    videos.forEach(function (video) {\n      if (!video.stream) {\n        video.stream = {};\n      }\n\n      if (video.stream.fullcanvas) {\n        fullcanvas = video;\n      } else {\n        // todo: video.stream.active or video.stream.live to fix blank frames issues?\n        remaining.push(video);\n      }\n    });\n\n    if (fullcanvas) {\n      canvas.width = fullcanvas.stream.width;\n      canvas.height = fullcanvas.stream.height;\n    } else if (remaining.length) {\n      canvas.width = videosLength > 1 ? remaining[0].width * 2 : remaining[0].width;\n      var height = 1;\n\n      if (videosLength === 3 || videosLength === 4) {\n        height = 2;\n      }\n\n      if (videosLength === 5 || videosLength === 6) {\n        height = 3;\n      }\n\n      if (videosLength === 7 || videosLength === 8) {\n        height = 4;\n      }\n\n      if (videosLength === 9 || videosLength === 10) {\n        height = 5;\n      }\n\n      canvas.height = remaining[0].height * height;\n    } else {\n      canvas.width = self.width || 360;\n      canvas.height = self.height || 240;\n    }\n\n    if (fullcanvas && fullcanvas instanceof HTMLVideoElement) {\n      drawImage(fullcanvas);\n    }\n\n    remaining.forEach(function (video, idx) {\n      drawImage(video, idx);\n    });\n    setTimeout(drawVideosToCanvas, self.frameInterval);\n  }\n\n  function drawImage(video, idx) {\n    if (isStopDrawingFrames) {\n      return;\n    }\n\n    var x = 0;\n    var y = 0;\n    var width = video.width;\n    var height = video.height;\n\n    if (idx === 1) {\n      x = video.width;\n    }\n\n    if (idx === 2) {\n      y = video.height;\n    }\n\n    if (idx === 3) {\n      x = video.width;\n      y = video.height;\n    }\n\n    if (idx === 4) {\n      y = video.height * 2;\n    }\n\n    if (idx === 5) {\n      x = video.width;\n      y = video.height * 2;\n    }\n\n    if (idx === 6) {\n      y = video.height * 3;\n    }\n\n    if (idx === 7) {\n      x = video.width;\n      y = video.height * 3;\n    }\n\n    if (typeof video.stream.left !== 'undefined') {\n      x = video.stream.left;\n    }\n\n    if (typeof video.stream.top !== 'undefined') {\n      y = video.stream.top;\n    }\n\n    if (typeof video.stream.width !== 'undefined') {\n      width = video.stream.width;\n    }\n\n    if (typeof video.stream.height !== 'undefined') {\n      height = video.stream.height;\n    }\n\n    context.drawImage(video, x, y, width, height);\n\n    if (typeof video.stream.onRender === 'function') {\n      video.stream.onRender(context, x, y, width, height, idx);\n    }\n  }\n\n  function getMixedStream() {\n    isStopDrawingFrames = false;\n    var mixedVideoStream = getMixedVideoStream();\n    var mixedAudioStream = getMixedAudioStream();\n\n    if (mixedAudioStream) {\n      mixedAudioStream.getTracks().filter(function (t) {\n        return t.kind === 'audio';\n      }).forEach(function (track) {\n        mixedVideoStream.addTrack(track);\n      });\n    }\n\n    var fullcanvas;\n    arrayOfMediaStreams.forEach(function (stream) {\n      if (stream.fullcanvas) {\n        fullcanvas = true;\n      }\n    }); // mixedVideoStream.prototype.appendStreams = appendStreams;\n    // mixedVideoStream.prototype.resetVideoStreams = resetVideoStreams;\n    // mixedVideoStream.prototype.clearRecordedData = clearRecordedData;\n\n    return mixedVideoStream;\n  }\n\n  function getMixedVideoStream() {\n    resetVideoStreams();\n    var capturedStream;\n\n    if ('captureStream' in canvas) {\n      capturedStream = canvas.captureStream();\n    } else if ('mozCaptureStream' in canvas) {\n      capturedStream = canvas.mozCaptureStream();\n    } else if (!self.disableLogs) {\n      console.error('Upgrade to latest Chrome or otherwise enable this flag: chrome://flags/#enable-experimental-web-platform-features');\n    }\n\n    var videoStream = new MediaStream();\n    capturedStream.getTracks().filter(function (t) {\n      return t.kind === 'video';\n    }).forEach(function (track) {\n      videoStream.addTrack(track);\n    });\n    canvas.stream = videoStream;\n    return videoStream;\n  }\n\n  function getMixedAudioStream() {\n    // via: @pehrsons\n    if (!Storage.AudioContextConstructor) {\n      Storage.AudioContextConstructor = new Storage.AudioContext();\n    }\n\n    self.audioContext = Storage.AudioContextConstructor;\n    self.audioSources = [];\n\n    if (self.useGainNode === true) {\n      self.gainNode = self.audioContext.createGain();\n      self.gainNode.connect(self.audioContext.destination);\n      self.gainNode.gain.value = 0; // don't hear self\n    }\n\n    var audioTracksLength = 0;\n    arrayOfMediaStreams.forEach(function (stream) {\n      if (!stream.getTracks().filter(function (t) {\n        return t.kind === 'audio';\n      }).length) {\n        return;\n      }\n\n      audioTracksLength++;\n      var audioSource = self.audioContext.createMediaStreamSource(stream);\n\n      if (self.useGainNode === true) {\n        audioSource.connect(self.gainNode);\n      }\n\n      self.audioSources.push(audioSource);\n    });\n\n    if (!audioTracksLength) {\n      // because \"self.audioContext\" is not initialized\n      // that's why we've to ignore rest of the code\n      return;\n    }\n\n    self.audioDestination = self.audioContext.createMediaStreamDestination();\n    self.audioSources.forEach(function (audioSource) {\n      audioSource.connect(self.audioDestination);\n    });\n    return self.audioDestination.stream;\n  }\n\n  function getVideo(stream) {\n    var video = document.createElement('video');\n    setSrcObject(stream, video);\n    video.className = elementClass;\n    video.muted = true;\n    video.volume = 0;\n    video.width = stream.width || self.width || 360;\n    video.height = stream.height || self.height || 240;\n    video.play();\n    return video;\n  }\n\n  this.appendStreams = function (streams) {\n    if (!streams) {\n      throw 'First parameter is required.';\n    }\n\n    if (!(streams instanceof Array)) {\n      streams = [streams];\n    }\n\n    streams.forEach(function (stream) {\n      var newStream = new MediaStream();\n\n      if (stream.getTracks().filter(function (t) {\n        return t.kind === 'video';\n      }).length) {\n        var video = getVideo(stream);\n        video.stream = stream;\n        videos.push(video);\n        newStream.addTrack(stream.getTracks().filter(function (t) {\n          return t.kind === 'video';\n        })[0]);\n      }\n\n      if (stream.getTracks().filter(function (t) {\n        return t.kind === 'audio';\n      }).length) {\n        var audioSource = self.audioContext.createMediaStreamSource(stream);\n        self.audioDestination = self.audioContext.createMediaStreamDestination();\n        audioSource.connect(self.audioDestination);\n        newStream.addTrack(self.audioDestination.stream.getTracks().filter(function (t) {\n          return t.kind === 'audio';\n        })[0]);\n      }\n\n      arrayOfMediaStreams.push(newStream);\n    });\n  };\n\n  this.releaseStreams = function () {\n    videos = [];\n    isStopDrawingFrames = true;\n\n    if (self.gainNode) {\n      self.gainNode.disconnect();\n      self.gainNode = null;\n    }\n\n    if (self.audioSources.length) {\n      self.audioSources.forEach(function (source) {\n        source.disconnect();\n      });\n      self.audioSources = [];\n    }\n\n    if (self.audioDestination) {\n      self.audioDestination.disconnect();\n      self.audioDestination = null;\n    }\n\n    if (self.audioContext) {\n      self.audioContext.close();\n    }\n\n    self.audioContext = null;\n    context.clearRect(0, 0, canvas.width, canvas.height);\n\n    if (canvas.stream) {\n      canvas.stream.stop();\n      canvas.stream = null;\n    }\n  };\n\n  this.resetVideoStreams = function (streams) {\n    if (streams && !(streams instanceof Array)) {\n      streams = [streams];\n    }\n\n    resetVideoStreams(streams);\n  };\n\n  function resetVideoStreams(streams) {\n    videos = [];\n    streams = streams || arrayOfMediaStreams; // via: @adrian-ber\n\n    streams.forEach(function (stream) {\n      if (!stream.getTracks().filter(function (t) {\n        return t.kind === 'video';\n      }).length) {\n        return;\n      }\n\n      var video = getVideo(stream);\n      video.stream = stream;\n      videos.push(video);\n    });\n  } // for debugging\n\n\n  this.name = 'MultiStreamsMixer';\n\n  this.toString = function () {\n    return this.name;\n  };\n\n  this.getMixedStream = getMixedStream;\n}\n\nif (typeof RecordRTC === 'undefined') {\n  if (typeof module !== 'undefined'\n  /* && !!module.exports*/\n  ) {\n      module.exports = MultiStreamsMixer;\n    }\n\n  if (typeof define === 'function' && define.amd) {\n    define('MultiStreamsMixer', [], function () {\n      return MultiStreamsMixer;\n    });\n  }\n} // ______________________\n// MultiStreamRecorder.js\n\n/*\r\n * Video conference recording, using captureStream API along with WebAudio and Canvas2D API.\r\n */\n\n/**\r\n * MultiStreamRecorder can record multiple videos in single container.\r\n * @summary Multi-videos recorder.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef MultiStreamRecorder\r\n * @class\r\n * @example\r\n * var options = {\r\n *     mimeType: 'video/webm'\r\n * }\r\n * var recorder = new MultiStreamRecorder(ArrayOfMediaStreams, options);\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n *\r\n *     // or\r\n *     var blob = recorder.blob;\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStreams} mediaStreams - Array of MediaStreams.\r\n * @param {object} config - {disableLogs:true, frameInterval: 1, mimeType: \"video/webm\"}\r\n */\n\n\nfunction MultiStreamRecorder(arrayOfMediaStreams, options) {\n  arrayOfMediaStreams = arrayOfMediaStreams || [];\n  var self = this;\n  var mixer;\n  var mediaRecorder;\n  options = options || {\n    elementClass: 'multi-streams-mixer',\n    mimeType: 'video/webm',\n    video: {\n      width: 360,\n      height: 240\n    }\n  };\n\n  if (!options.frameInterval) {\n    options.frameInterval = 10;\n  }\n\n  if (!options.video) {\n    options.video = {};\n  }\n\n  if (!options.video.width) {\n    options.video.width = 360;\n  }\n\n  if (!options.video.height) {\n    options.video.height = 240;\n  }\n  /**\r\n   * This method records all MediaStreams.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n\n  this.record = function () {\n    // github/muaz-khan/MultiStreamsMixer\n    mixer = new MultiStreamsMixer(arrayOfMediaStreams, options.elementClass || 'multi-streams-mixer');\n\n    if (getAllVideoTracks().length) {\n      mixer.frameInterval = options.frameInterval || 10;\n      mixer.width = options.video.width || 360;\n      mixer.height = options.video.height || 240;\n      mixer.startDrawingFrames();\n    }\n\n    if (options.previewStream && typeof options.previewStream === 'function') {\n      options.previewStream(mixer.getMixedStream());\n    } // record using MediaRecorder API\n\n\n    mediaRecorder = new MediaStreamRecorder(mixer.getMixedStream(), options);\n    mediaRecorder.record();\n  };\n\n  function getAllVideoTracks() {\n    var tracks = [];\n    arrayOfMediaStreams.forEach(function (stream) {\n      getTracks(stream, 'video').forEach(function (track) {\n        tracks.push(track);\n      });\n    });\n    return tracks;\n  }\n  /**\r\n   * This method stops recording MediaStream.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n\n  this.stop = function (callback) {\n    if (!mediaRecorder) {\n      return;\n    }\n\n    mediaRecorder.stop(function (blob) {\n      self.blob = blob;\n      callback(blob);\n      self.clearRecordedData();\n    });\n  };\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n\n  this.pause = function () {\n    if (mediaRecorder) {\n      mediaRecorder.pause();\n    }\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    if (mediaRecorder) {\n      mediaRecorder.resume();\n    }\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    if (mediaRecorder) {\n      mediaRecorder.clearRecordedData();\n      mediaRecorder = null;\n    }\n\n    if (mixer) {\n      mixer.releaseStreams();\n      mixer = null;\n    }\n  };\n  /**\r\n   * Add extra media-streams to existing recordings.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @param {MediaStreams} mediaStreams - Array of MediaStreams\r\n   * @example\r\n   * recorder.addStreams([newAudioStream, newVideoStream]);\r\n   */\n\n\n  this.addStreams = function (streams) {\n    if (!streams) {\n      throw 'First parameter is required.';\n    }\n\n    if (!(streams instanceof Array)) {\n      streams = [streams];\n    }\n\n    arrayOfMediaStreams.concat(streams);\n\n    if (!mediaRecorder || !mixer) {\n      return;\n    }\n\n    mixer.appendStreams(streams);\n\n    if (options.previewStream && typeof options.previewStream === 'function') {\n      options.previewStream(mixer.getMixedStream());\n    }\n  };\n  /**\r\n   * Reset videos during live recording. Replace old videos e.g. replace cameras with full-screen.\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @param {MediaStreams} mediaStreams - Array of MediaStreams\r\n   * @example\r\n   * recorder.resetVideoStreams([newVideo1, newVideo2]);\r\n   */\n\n\n  this.resetVideoStreams = function (streams) {\n    if (!mixer) {\n      return;\n    }\n\n    if (streams && !(streams instanceof Array)) {\n      streams = [streams];\n    }\n\n    mixer.resetVideoStreams(streams);\n  };\n  /**\r\n   * Returns MultiStreamsMixer\r\n   * @method\r\n   * @memberof MultiStreamRecorder\r\n   * @example\r\n   * let mixer = recorder.getMixer();\r\n   * mixer.appendStreams([newStream]);\r\n   */\n\n\n  this.getMixer = function () {\n    return mixer;\n  }; // for debugging\n\n\n  this.name = 'MultiStreamRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.MultiStreamRecorder = MultiStreamRecorder;\n} // _____________________\n// RecordRTC.promises.js\n\n/**\r\n * RecordRTCPromisesHandler adds promises support in {@link RecordRTC}. Try a {@link https://github.com/muaz-khan/RecordRTC/blob/master/simple-demos/RecordRTCPromisesHandler.html|demo here}\r\n * @summary Promises for {@link RecordRTC}\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef RecordRTCPromisesHandler\r\n * @class\r\n * @example\r\n * var recorder = new RecordRTCPromisesHandler(mediaStream, options);\r\n * recorder.startRecording()\r\n *         .then(successCB)\r\n *         .catch(errorCB);\r\n * // Note: You can access all RecordRTC API using \"recorder.recordRTC\" e.g. \r\n * recorder.recordRTC.onStateChanged = function(state) {};\r\n * recorder.recordRTC.setRecordingDuration(5000);\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - Single media-stream object, array of media-streams, html-canvas-element, etc.\r\n * @param {object} config - {type:\"video\", recorderType: MediaStreamRecorder, disableLogs: true, numberOfAudioChannels: 1, bufferSize: 0, sampleRate: 0, video: HTMLVideoElement, etc.}\r\n * @throws Will throw an error if \"new\" keyword is not used to initiate \"RecordRTCPromisesHandler\". Also throws error if first argument \"MediaStream\" is missing.\r\n * @requires {@link RecordRTC}\r\n */\n\n\nfunction RecordRTCPromisesHandler(mediaStream, options) {\n  if (!this) {\n    throw 'Use \"new RecordRTCPromisesHandler()\"';\n  }\n\n  if (typeof mediaStream === 'undefined') {\n    throw 'First argument \"MediaStream\" is required.';\n  }\n\n  var self = this;\n  /**\r\n   * @property {Blob} blob - Access/reach the native {@link RecordRTC} object.\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * let internal = recorder.recordRTC.getInternalRecorder();\r\n   * alert(internal instanceof MediaStreamRecorder);\r\n   * recorder.recordRTC.onStateChanged = function(state) {};\r\n   */\n\n  self.recordRTC = new RecordRTC(mediaStream, options);\n  /**\r\n   * This method records MediaStream.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.startRecording()\r\n   *         .then(successCB)\r\n   *         .catch(errorCB);\r\n   */\n\n  this.startRecording = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        self.recordRTC.startRecording();\n        resolve();\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method stops the recording.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.stopRecording().then(function() {\r\n   *     var blob = recorder.getBlob();\r\n   * }).catch(errorCB);\r\n   */\n\n\n  this.stopRecording = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        self.recordRTC.stopRecording(function (url) {\n          self.blob = self.recordRTC.getBlob();\n\n          if (!self.blob || !self.blob.size) {\n            reject('Empty blob.', self.blob);\n            return;\n          }\n\n          resolve(url);\n        });\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method pauses the recording. You can resume recording using \"resumeRecording\" method.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.pauseRecording()\r\n   *         .then(successCB)\r\n   *         .catch(errorCB);\r\n   */\n\n\n  this.pauseRecording = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        self.recordRTC.pauseRecording();\n        resolve();\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method resumes the recording.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.resumeRecording()\r\n   *         .then(successCB)\r\n   *         .catch(errorCB);\r\n   */\n\n\n  this.resumeRecording = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        self.recordRTC.resumeRecording();\n        resolve();\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method returns data-url for the recorded blob.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.stopRecording().then(function() {\r\n   *     recorder.getDataURL().then(function(dataURL) {\r\n   *         window.open(dataURL);\r\n   *     }).catch(errorCB);;\r\n   * }).catch(errorCB);\r\n   */\n\n\n  this.getDataURL = function (callback) {\n    return new Promise(function (resolve, reject) {\n      try {\n        self.recordRTC.getDataURL(function (dataURL) {\n          resolve(dataURL);\n        });\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method returns the recorded blob.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.stopRecording().then(function() {\r\n   *     recorder.getBlob().then(function(blob) {})\r\n   * }).catch(errorCB);\r\n   */\n\n\n  this.getBlob = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        resolve(self.recordRTC.getBlob());\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method returns the internal recording object.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * let internalRecorder = await recorder.getInternalRecorder();\r\n   * if(internalRecorder instanceof MultiStreamRecorder) {\r\n   *     internalRecorder.addStreams([newAudioStream]);\r\n   *     internalRecorder.resetVideoStreams([screenStream]);\r\n   * }\r\n   * @returns {Object} \r\n   */\n\n\n  this.getInternalRecorder = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        resolve(self.recordRTC.getInternalRecorder());\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * This method resets the recorder. So that you can reuse single recorder instance many times.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * await recorder.reset();\r\n   * recorder.startRecording(); // record again\r\n   */\n\n\n  this.reset = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        resolve(self.recordRTC.reset());\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * Destroy RecordRTC instance. Clear all recorders and objects.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * recorder.destroy().then(successCB).catch(errorCB);\r\n   */\n\n\n  this.destroy = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        resolve(self.recordRTC.destroy());\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * Get recorder's readonly state.\r\n   * @method\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * let state = await recorder.getState();\r\n   * // or\r\n   * recorder.getState().then(state => { console.log(state); })\r\n   * @returns {String} Returns recording state.\r\n   */\n\n\n  this.getState = function () {\n    return new Promise(function (resolve, reject) {\n      try {\n        resolve(self.recordRTC.getState());\n      } catch (e) {\n        reject(e);\n      }\n    });\n  };\n  /**\r\n   * @property {Blob} blob - Recorded data as \"Blob\" object.\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @example\r\n   * await recorder.stopRecording();\r\n   * let blob = recorder.getBlob(); // or \"recorder.recordRTC.blob\"\r\n   * invokeSaveAsDialog(blob);\r\n   */\n\n\n  this.blob = null;\n  /**\r\n   * RecordRTC version number\r\n   * @property {String} version - Release version number.\r\n   * @memberof RecordRTCPromisesHandler\r\n   * @static\r\n   * @readonly\r\n   * @example\r\n   * alert(recorder.version);\r\n   */\n\n  this.version = '5.6.2';\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.RecordRTCPromisesHandler = RecordRTCPromisesHandler;\n} // ______________________\n// WebAssemblyRecorder.js\n\n/**\r\n * WebAssemblyRecorder lets you create webm videos in JavaScript via WebAssembly. The library consumes raw RGBA32 buffers (4 bytes per pixel) and turns them into a webm video with the given framerate and quality. This makes it compatible out-of-the-box with ImageData from a CANVAS. With realtime mode you can also use webm-wasm for streaming webm videos.\r\n * @summary Video recording feature in Chrome, Firefox and maybe Edge.\r\n * @license {@link https://github.com/muaz-khan/RecordRTC/blob/master/LICENSE|MIT}\r\n * @author {@link https://MuazKhan.com|Muaz Khan}\r\n * @typedef WebAssemblyRecorder\r\n * @class\r\n * @example\r\n * var recorder = new WebAssemblyRecorder(mediaStream);\r\n * recorder.record();\r\n * recorder.stop(function(blob) {\r\n *     video.src = URL.createObjectURL(blob);\r\n * });\r\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\r\n * @param {MediaStream} mediaStream - MediaStream object fetched using getUserMedia API or generated using captureStreamUntilEnded or WebAudio API.\r\n * @param {object} config - {webAssemblyPath:'webm-wasm.wasm',workerPath: 'webm-worker.js', frameRate: 30, width: 1920, height: 1080, bitrate: 1024, realtime: true}\r\n */\n\n\nfunction WebAssemblyRecorder(stream, config) {\n  // based on: github.com/GoogleChromeLabs/webm-wasm\n  if (typeof ReadableStream === 'undefined' || typeof WritableStream === 'undefined') {\n    // because it fixes readable/writable streams issues\n    console.error('Following polyfill is strongly recommended: https://unpkg.com/@mattiasbuelens/web-streams-polyfill/dist/polyfill.min.js');\n  }\n\n  config = config || {};\n  config.width = config.width || 640;\n  config.height = config.height || 480;\n  config.frameRate = config.frameRate || 30;\n  config.bitrate = config.bitrate || 1200;\n  config.realtime = config.realtime || true;\n\n  function createBufferURL(buffer, type) {\n    return URL.createObjectURL(new Blob([buffer], {\n      type: type || ''\n    }));\n  }\n\n  var finished;\n\n  function cameraStream() {\n    return new ReadableStream({\n      start: function start(controller) {\n        var cvs = document.createElement('canvas');\n        var video = document.createElement('video');\n        var first = true;\n        video.srcObject = stream;\n        video.muted = true;\n        video.height = config.height;\n        video.width = config.width;\n        video.volume = 0;\n\n        video.onplaying = function () {\n          cvs.width = config.width;\n          cvs.height = config.height;\n          var ctx = cvs.getContext('2d');\n          var frameTimeout = 1000 / config.frameRate;\n          var cameraTimer = setInterval(function f() {\n            if (finished) {\n              clearInterval(cameraTimer);\n              controller.close();\n            }\n\n            if (first) {\n              first = false;\n\n              if (config.onVideoProcessStarted) {\n                config.onVideoProcessStarted();\n              }\n            }\n\n            ctx.drawImage(video, 0, 0);\n\n            if (controller._controlledReadableStream.state !== 'closed') {\n              try {\n                controller.enqueue(ctx.getImageData(0, 0, config.width, config.height));\n              } catch (e) {}\n            }\n          }, frameTimeout);\n        };\n\n        video.play();\n      }\n    });\n  }\n\n  var worker;\n\n  function startRecording(stream, buffer) {\n    if (!config.workerPath && !buffer) {\n      finished = false; // is it safe to use @latest ?\n\n      fetch('https://unpkg.com/webm-wasm@latest/dist/webm-worker.js').then(function (r) {\n        r.arrayBuffer().then(function (buffer) {\n          startRecording(stream, buffer);\n        });\n      });\n      return;\n    }\n\n    if (!config.workerPath && buffer instanceof ArrayBuffer) {\n      var blob = new Blob([buffer], {\n        type: 'text/javascript'\n      });\n      config.workerPath = URL.createObjectURL(blob);\n    }\n\n    if (!config.workerPath) {\n      console.error('workerPath parameter is missing.');\n    }\n\n    worker = new Worker(config.workerPath);\n    worker.postMessage(config.webAssemblyPath || 'https://unpkg.com/webm-wasm@latest/dist/webm-wasm.wasm');\n    worker.addEventListener('message', function (event) {\n      if (event.data === 'READY') {\n        worker.postMessage({\n          width: config.width,\n          height: config.height,\n          bitrate: config.bitrate || 1200,\n          timebaseDen: config.frameRate || 30,\n          realtime: config.realtime\n        });\n        cameraStream().pipeTo(new WritableStream({\n          write: function write(image) {\n            if (finished) {\n              console.error('Got image, but recorder is finished!');\n              return;\n            }\n\n            worker.postMessage(image.data.buffer, [image.data.buffer]);\n          }\n        }));\n      } else if (!!event.data) {\n        if (!isPaused) {\n          arrayOfBuffers.push(event.data);\n        }\n      }\n    });\n  }\n  /**\r\n   * This method records video.\r\n   * @method\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.record();\r\n   */\n\n\n  this.record = function () {\n    arrayOfBuffers = [];\n    isPaused = false;\n    this.blob = null;\n    startRecording(stream);\n\n    if (typeof config.initCallback === 'function') {\n      config.initCallback();\n    }\n  };\n\n  var isPaused;\n  /**\r\n   * This method pauses the recording process.\r\n   * @method\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.pause();\r\n   */\n\n  this.pause = function () {\n    isPaused = true;\n  };\n  /**\r\n   * This method resumes the recording process.\r\n   * @method\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.resume();\r\n   */\n\n\n  this.resume = function () {\n    isPaused = false;\n  };\n\n  function terminate(callback) {\n    if (!worker) {\n      if (callback) {\n        callback();\n      }\n\n      return;\n    } // Wait for null event data to indicate that the encoding is complete\n\n\n    worker.addEventListener('message', function (event) {\n      if (event.data === null) {\n        worker.terminate();\n        worker = null;\n\n        if (callback) {\n          callback();\n        }\n      }\n    });\n    worker.postMessage(null);\n  }\n\n  var arrayOfBuffers = [];\n  /**\r\n   * This method stops recording video.\r\n   * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\r\n   * @method\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.stop(function(blob) {\r\n   *     video.src = URL.createObjectURL(blob);\r\n   * });\r\n   */\n\n  this.stop = function (callback) {\n    finished = true;\n    var recorder = this;\n    terminate(function () {\n      recorder.blob = new Blob(arrayOfBuffers, {\n        type: 'video/webm'\n      });\n      callback(recorder.blob);\n    });\n  }; // for debugging\n\n\n  this.name = 'WebAssemblyRecorder';\n\n  this.toString = function () {\n    return this.name;\n  };\n  /**\r\n   * This method resets currently recorded data.\r\n   * @method\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.clearRecordedData();\r\n   */\n\n\n  this.clearRecordedData = function () {\n    arrayOfBuffers = [];\n    isPaused = false;\n    this.blob = null; // todo: if recording-ON then STOP it first\n  };\n  /**\r\n   * @property {Blob} blob - The recorded blob object.\r\n   * @memberof WebAssemblyRecorder\r\n   * @example\r\n   * recorder.stop(function(){\r\n   *     var blob = recorder.blob;\r\n   * });\r\n   */\n\n\n  this.blob = null;\n}\n\nif (typeof RecordRTC !== 'undefined') {\n  RecordRTC.WebAssemblyRecorder = WebAssemblyRecorder;\n}","map":null,"metadata":{},"sourceType":"module"}